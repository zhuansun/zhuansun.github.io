<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>kafka从入门到入土 | 张三碎碎念</title><meta name="author" content="zs"><meta name="copyright" content="zs"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="kafka从入门到入土 基本概念名词术语消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。 主题：Topic。Topic 是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。 分区：Partition。是一个物理概念，可以理解为一个有序不变的消息序列。每个 Topic 下可以有多个 Partition。 分区位移：Offset。表示 Partition">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka从入门到入土">
<meta property="og:url" content="https://zspcer.gitee.io/note/JAVA/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/KAFKA/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/index.html">
<meta property="og:site_name" content="张三碎碎念">
<meta property="og:description" content="kafka从入门到入土 基本概念名词术语消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。 主题：Topic。Topic 是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。 分区：Partition。是一个物理概念，可以理解为一个有序不变的消息序列。每个 Topic 下可以有多个 Partition。 分区位移：Offset。表示 Partition">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2022/10/31/ZgTsuqvdNpWHfRB.jpg">
<meta property="article:published_time" content="2023-02-17T15:10:04.668Z">
<meta property="article:modified_time" content="2023-02-17T15:10:04.668Z">
<meta property="article:author" content="zs">
<meta property="article:tag" content="kafka">
<meta property="article:tag" content="生产者">
<meta property="article:tag" content="消费者">
<meta property="article:tag" content="消息">
<meta property="article:tag" content="中间件">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/10/31/ZgTsuqvdNpWHfRB.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zspcer.gitee.io/note/JAVA/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/KAFKA/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'kafka从入门到入土',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-02-17 15:10:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="张三碎碎念" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">82</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">27</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/alist/"><i class="fa-fw fas fa-folder"></i><span> 网盘</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/10/31/ZgTsuqvdNpWHfRB.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">张三碎碎念</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/alist/"><i class="fa-fw fas fa-folder"></i><span> 网盘</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">kafka从入门到入土</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-17T15:10:04.668Z" title="发表于 2023-02-17 15:10:04">2023-02-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-02-17T15:10:04.668Z" title="更新于 2023-02-17 15:10:04">2023-02-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/JAVA/">JAVA</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/JAVA/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/">消息中间件</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/JAVA/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/KAFKA/">KAFKA</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="kafka从入门到入土"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="kafka从入门到入土"><a href="#kafka从入门到入土" class="headerlink" title="kafka从入门到入土"></a>kafka从入门到入土</h1><hr>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="名词术语"><a href="#名词术语" class="headerlink" title="名词术语"></a>名词术语</h3><p>消息：<code>Record</code>。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。</p>
<p>主题：<code>Topic</code>。Topic 是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。</p>
<p>分区：<code>Partition</code>。是一个物理概念，可以理解为一个有序不变的消息序列。每个 Topic 下可以有多个 Partition。</p>
<p>分区位移：<code>Offset</code>。表示 Partition 中每条消息的位置信息，这个值是存在消息中的，是一个单调递增且不变的值。</p>
<p>副本：<code>Replica</code>。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的<code>Replica</code>副本。<code>Replica</code>还分为<code>Leader Replica</code>和<code>Follower Replica</code>，各自有不同的角色划分。<code>Replica</code>是在<code>Partition</code>层级下的，即每个<code>Partition</code>可配置多个<code>Replica</code>实现高可用。</p>
<p>生产者：<code>Producer</code>。向<code>Topic</code>发布新消息的应用程序。</p>
<p>消费者：<code>Consumer</code>。从<code>Topic</code>订阅新消息的应用程序。</p>
<p>消费者位移：<code>Consumer Offset</code>。表示<code>Consumer</code>的消费进度，每个<code>Consumer</code>都有自己的<code>Consumer Offset</code>。</p>
<p>消费者组：<code>Consumer Group</code>。多个<code>Consumer</code>实例共同组成的一个组<code>Group</code>，同时消费多个<code>Partition</code>以实现高吞吐。</p>
<p>重平衡：<code>Rebalance</code>。<code>Consumer Group</code>内某个<code>Consumer</code>实例挂掉后，其他<code>Consumer</code>实例自动重新分配订阅<code>Topic Partiton</code>的过程。<code>Rebalance</code> 是 Kafka 消费端实现高可用的重要手段。</p>
<img src="kafka从入门到入土.assets/58c35d3ab0921bf0476e3ba14069d291.jpg" alt="img" style="zoom: 20%;" />



<h3 id="三层消息架构"><a href="#三层消息架构" class="headerlink" title="三层消息架构"></a>三层消息架构</h3><ul>
<li>第一层：主题层<code>Topic</code><ul>
<li>每个<code>Topic</code>可以配置<code>M</code>的<code>Partition</code>，而每个<code>Partition</code>又可以配置<code>N</code>个<code>Replica</code></li>
</ul>
</li>
<li>第二层：分区层<code>Partition</code><ul>
<li>每个<code>Partition</code>下的<code>N</code>个<code>Replica</code>中，只能有一个充当<code>Leader Replica</code>，<code>Leader Replica</code>负责对外提供服务；</li>
<li>剩下的<code>N-1</code>个<code>Replica</code>，都是作为<code>Follower Replica</code>，<code>Follower Replica</code>只是作为数据冗余，不对外提供服务；</li>
</ul>
</li>
<li>第三层：消息层<ul>
<li>每个<code>Partition</code>中包含若干消息，每个消息的<code>Offset</code>（注意不是<code>Consumer Offset</code>）都是从0开始，依次递增；</li>
</ul>
</li>
</ul>
<h3 id="数据持久化（Log）"><a href="#数据持久化（Log）" class="headerlink" title="数据持久化（Log）"></a>数据持久化（Log）</h3><p><code>kafka</code>使用消息日志<code>Log</code>来保存数据，一个<code>Log</code>就是磁盘上一个只能追加写消息的物理文件。</p>
<p>一个<code>Log</code>包含了多个日志段<code>Log Segment</code>，消息其实是被追加写到最新的<code>Log Segment</code>中的；</p>
<p>当写满一个<code>Log Segment</code>的时候，会自动切分一个新的<code>Log Segment</code>中，老的<code>Log Segment</code>就会被封存；</p>
<p><code>kafka</code>会有一个定时任务，定期检查老的<code>Log Segment</code>是否能够被删除，从而释放磁盘空间；</p>
<h3 id="两种消息模型"><a href="#两种消息模型" class="headerlink" title="两种消息模型"></a>两种消息模型</h3><p>点对点<code>peer to peer</code></p>
<ul>
<li>同一个消息只能被下游的一个<code>Consumer</code>消费；</li>
<li>kafka实现点对点，用到的是<code>Consumer Group</code>的概念</li>
</ul>
<p>发布订阅模型<code>pub/sub</code></p>
<ul>
<li>我们常用到的其实就是这种发布订阅模型</li>
</ul>
<h2 id="发展历史和定位"><a href="#发展历史和定位" class="headerlink" title="发展历史和定位"></a>发展历史和定位</h2><p>kakka既是一个消息引擎系统，同时又是一个分布式流处理平台；</p>
<h3 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h3><ul>
<li><p>是<code>Linkedln</code>公司内部的孵化项目。</p>
</li>
<li><p><code>Linkedln</code>一开始是有 数据强实时性处理方面的需求，用了<code>activeMq</code>，但不理想，所以准备自己搞一套。</p>
</li>
<li><p><code>Kafka</code> 自诞生伊始是以<strong>消息引擎系统</strong>的面目出现在大众视野中的。如果翻看 <code>0.10.0.0</code> 之前的官网说明，你会发现 <code>Kafka</code> 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志<code>Commit Log</code>服务。</p>
</li>
<li><p><code>Kafka</code>在设计之初提供三个方面的特性：</p>
<ul>
<li>提供一套 API 实现<code>Producer</code>和<code>Consumer</code>；</li>
<li>降低网络传输和磁盘存储开销；</li>
<li>实现高伸缩性架构。</li>
</ul>
</li>
<li><p>后来用的人越来越多，<code>kafka</code>思考引入了流处理；</p>
</li>
<li><p><code>Kafka</code> 社区于 <code>0.10.0.0</code> 版本正式推出了流处理组件 <code>Kafka Streams</code>，也正是从这个版本开始，<code>Kafka</code> 正式“变身”为分布式的流处理平台，而不仅仅是消息引擎系统了。</p>
</li>
</ul>
<h3 id="与其他的流处理框架的优点"><a href="#与其他的流处理框架的优点" class="headerlink" title="与其他的流处理框架的优点"></a>与其他的流处理框架的优点</h3><ul>
<li>第一点是更容易实现端到端的正确性<code>Correctness</code></li>
<li><code>kafka</code>自己对于流式计算的定位</li>
</ul>
<h3 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h3><ul>
<li>消息引擎系统</li>
<li>流处理平台</li>
<li>分布式存储系统（很少）</li>
</ul>
<h2 id="kafka版本"><a href="#kafka版本" class="headerlink" title="kafka版本"></a>kafka版本</h2><h3 id="发行版本"><a href="#发行版本" class="headerlink" title="发行版本"></a>发行版本</h3><p><code>kafka</code>存在多个不同的发行版本，类似<code>linux</code>系统中的<code>centos</code>，<code>redhat</code>，<code>ununtu</code>等；</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>优点</th>
<th>缺点</th>
<th>选择</th>
</tr>
</thead>
<tbody><tr>
<td>apache kafka</td>
<td>Apache Kafka 是最“正宗”的 Kafka，是我们学习和使用 Kafka 的基础。</td>
<td>优势在于迭代速度快，社区响应度高，使用它可以让你有更高的把控度</td>
<td>缺陷在于仅提供基础核心组件，缺失一些高级的特性。</td>
<td>如果你仅仅需要一个消息引擎系统亦或是简单的流处理应用场景，同时需要对系统有较大把控度，那么我推荐你使用 Apache Kafka。</td>
</tr>
<tr>
<td>Confluent Kafka</td>
<td>Confluent 公司：2014 年，Kafka 的 3 个创始人 Jay Kreps、Naha Narkhede 和饶军离开 LinkedIn 创办了 Confluent 公司，专注于提供基于 Kafka 的企业级流处理解决方案。Confluent Kafka 提供了一些 Apache Kafka 没有的高级特性，比如跨数据中心备份、Schema 注册中心以及集群监控工具等。</td>
<td>优势在于集成了很多高级特性且由 Kafka 原班人马打造，质量上有保证；</td>
<td>缺陷在于相关文档资料不全，普及率较低，没有太多可供参考的范例。</td>
<td>如果你需要用到 Kafka 的一些高级特性，那么推荐你使用 Confluent Kafka。</td>
</tr>
<tr>
<td>CDH Kafka &#x2F; HDP Kafka</td>
<td>Cloudera 提供的 CDH 和 Hortonworks 提供的 HDP 是非常著名的大数据平台，里面集成了目前主流的大数据框架，能够帮助用户实现从分布式存储、集群调度、流处理到机器学习、实时数据库等全方位的数据处理，不管是 CDH 还是 HDP 里面都集成了 Apache Kafka，因此我把这两款产品中的 Kafka 称为 CDH Kafka 和 HDP Kafka。</td>
<td>操作简单，节省运维成本</td>
<td>把控度低，演进速度较慢。</td>
<td>如果你需要快速地搭建消息引擎系统，或者你需要搭建的是多框架构成的数据平台且 Kafka 只是其中一个组件，那么我推荐你使用这些大数据云公司提供的 Kafka。</td>
</tr>
</tbody></table>
<h3 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h3><p>在官网上下载 <code>Kafka</code> 时，会看到这样的版本：</p>
<img src="kafka从入门到入土.assets/c10df9e6f72126e9c721fba38e27ac23.png" alt="img" style="zoom:80%;" />

<p>有些人会误将<code>Scala</code>版本看作是<code>Kafka</code>版本，那么就来解释一下这个版本号</p>
<ul>
<li><p><code>2.11/2.12</code>：代表着<code>Kafka</code>源代码的<code>Scala</code>编译器版本</p>
</li>
<li><p><code>2.3.0</code>：才是Kafka的版本号，<code>2</code>代表着大版本号；<code>3</code>代表着小版本号；<code>0</code>代表着修订版本号或补丁</p>
</li>
</ul>
<p>Kafka目前经历了7个大版本，0.7、0.8、0.9、0.10、0.11、1.0和2.0，其中小版本与Patch版本很多就不一一列举</p>
<p>在上面的7个大版本中，在哪个版本进行了重大的改进，来好好看一下</p>
<img src="kafka从入门到入土.assets/Kafka版本变迁.png" alt="img" style="zoom:80%;" />

<h4 id="0-7版本"><a href="#0-7版本" class="headerlink" title="0.7版本"></a>0.7版本</h4><p>这是个“上古”版本，只提供了基础的消息队列功能，还没有提供副本机制</p>
<h4 id="0-8版本"><a href="#0-8版本" class="headerlink" title="0.8版本"></a>0.8版本</h4><p>正式引入了副本机制，能够比较好地做到消息无丢失，新版本Producer API不稳定</p>
<h4 id="0-9版本"><a href="#0-9版本" class="headerlink" title="0.9版本"></a>0.9版本</h4><p>添加了基础的安全认证&#x2F;权限；新版本Producer API在这个版本中算比较稳定，但是0.9版的Consumer API BUG超多，即使提到社区也不会有人管，所以千万别用！</p>
<h4 id="0-10版本"><a href="#0-10版本" class="headerlink" title="0.10版本"></a>0.10版本</h4><p>是里程碑式的大版本，因为该版本引入了Kafka Streams，但还不能生产大规模部署使用，自0.10.2.2版本起，新版本Consumer API算是比较稳定了</p>
<h4 id="0-11版本"><a href="#0-11版本" class="headerlink" title="0.11版本"></a>0.11版本</h4><p>引入了两个重量级的功能变更：一个是提供幂等性Producer API以及事务（Transaction） API；另一个是对Kafka消息格式做了重构</p>
<p>Producer实现幂等性以及支持事务都是Kafka实现流处理结果正确性的基石，由于刚推出，事务API有一些Bug，另外事务API主要是为Kafka Streams应用服务的，不建议用</p>
<p>这个版本中各个大功能组件都变得非常稳定了，国内该版本的用户也很多，应该算是目前最主流的版本之一了</p>
<p>如果你对1.0版本是否适用于线上环境依然感到困惑，那么至少将你的环境升级到0.11.0.3，因为这个版本的消息引擎功能已经非常完善了</p>
<h4 id="1-0-x2F-2-0版本"><a href="#1-0-x2F-2-0版本" class="headerlink" title="1.0&#x2F;2.0版本"></a>1.0&#x2F;2.0版本</h4><p>合并说下1.0和2.0版本吧，因为这两个大版本主要还是Kafka Streams的各种改进，在消息引擎方面并未引入太多的重大功能特性</p>
<p>Kafka Streams的确在这两个版本有着非常大的变化，也必须承认Kafka Streams目前依然还在积极地发展着，如果你是Kafka Streams的用户，至少选择2.0.0版本吧</p>
<h4 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h4><p>不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多Kafka为你提供的性能优化收益</p>
<h2 id="kafka生产集群部署"><a href="#kafka生产集群部署" class="headerlink" title="kafka生产集群部署"></a>kafka生产集群部署</h2><p>上面了解了kafka的基本概念之后，下面看一下kafka的生产部署，需要怎么部署</p>
<p>同时在本小节之后，我们会搭建一个简单的kafka集群，用于后续的学习</p>
<p>kafka的集群搭建需要考虑一下几个因素</p>
<table>
<thead>
<tr>
<th>因素</th>
<th>考量点</th>
<th>建议</th>
</tr>
</thead>
<tbody><tr>
<td>操作系统</td>
<td>操作系统的IO模型</td>
<td>将kafka部署在linux上</td>
</tr>
<tr>
<td>磁盘</td>
<td>磁盘的IO性能</td>
<td>普通环境使用机械硬盘，不需要搭建RAID</td>
</tr>
<tr>
<td>磁盘容量</td>
<td>根据消息数，留存时间预估磁盘容量</td>
<td>实际使用中磁盘预留20%~30%的空间</td>
</tr>
<tr>
<td>带宽</td>
<td>根据实际带宽资源和业务SLA预估服务器数量</td>
<td>对于千兆网络，建议每台服务器按照700Mbps来计算，避免大流量下的丢包</td>
</tr>
</tbody></table>
<h3 id="操作系统的选择"><a href="#操作系统的选择" class="headerlink" title="操作系统的选择"></a>操作系统的选择</h3><p>操作系统：Windows，Linux，MacOs</p>
<p>选择：Linux</p>
<p>为什么：</p>
<ul>
<li>IO模型的使用</li>
<li>网络传输效率</li>
<li>社区支持度</li>
</ul>
<h4 id="IO模型的使用"><a href="#IO模型的使用" class="headerlink" title="IO模型的使用"></a>IO模型的使用</h4><ul>
<li>阻塞IO</li>
<li>非阻塞IO</li>
<li>IO多路复用</li>
<li>信号驱动IO</li>
<li>异步IO</li>
</ul>
<p>每种IO都有自己的典型使用场景，比如：</p>
<ul>
<li>Java中的Socket对象的阻塞模式和非阻塞模式就是对应前两种</li>
<li>Linux系统的select函数就属于IO多路复用</li>
<li>大名鼎鼎的epoll介入第三种和第四种之间</li>
<li>第五种模型，目前很少有Linux支持，然而Windos却在操作系统中提供了叫IOCP线程模型属于第五种</li>
</ul>
<p>说完了IO模型，再来看kafka与IO模型的关系</p>
<ul>
<li>kafka的底层使用的是java的selector<ul>
<li>java的selector在linux上的实现机制是：epoll</li>
<li>而在windos上的实现机制是：select（IO多路复用）</li>
</ul>
</li>
<li>所以，将kafka部署在linux机器上，更有优势</li>
</ul>
<h4 id="网络传输效率"><a href="#网络传输效率" class="headerlink" title="网络传输效率"></a>网络传输效率</h4><p>kafka的消息是通过网络传输的，而消息又是保存在磁盘中的，所以kafka非常依赖网络和磁盘的性能；</p>
<p>而linux恰巧有零拷贝（Zero copy）技术，就是当数据在磁盘和网络进行传输的时候，避免昂贵的的内核态数据拷贝从而实现数据的高速传输；</p>
<p>而windos要到java8的60更新版本才有这个功能；</p>
<h4 id="社区的支持度"><a href="#社区的支持度" class="headerlink" title="社区的支持度"></a>社区的支持度</h4><p>社区对于windos版的bug不做承诺，基本不会修复；</p>
<h3 id="磁盘的选择"><a href="#磁盘的选择" class="headerlink" title="磁盘的选择"></a>磁盘的选择</h3><ul>
<li>选择机械磁盘：kafka多为顺序读写，规避了机械磁盘的弊端，替换成SSD，效益不大</li>
<li>不用组RAID：kafka在软件层面通过分区副本保证了高可用，基本不需要磁盘组RAID</li>
</ul>
<h3 id="磁盘容量的选择"><a href="#磁盘容量的选择" class="headerlink" title="磁盘容量的选择"></a>磁盘容量的选择</h3><ul>
<li><p>磁盘容量：kafka的日志有保留时间的概念，根据具体的业务量，消息大小，计算好容量；</p>
<ul>
<li><p>新增消息量</p>
</li>
<li><p>消息留存时间</p>
</li>
<li><p>平均消息大小</p>
</li>
<li><p>备份数</p>
</li>
<li><p>是否启用压缩（压缩比）</p>
</li>
</ul>
</li>
</ul>
<h3 id="带宽的选择"><a href="#带宽的选择" class="headerlink" title="带宽的选择"></a>带宽的选择</h3><p>目前公司普遍的带宽配置都是千兆网（每秒处理1G数据），财大气粗的公司会有万兆网（每秒处理10G数据）；</p>
<p>假设你公司的机房环境是千兆网络，即 1Gbps，现在你有个业务，其业务目标或 SLA 是在 1 小时内处理 1TB 的业务数据。那么问题来了，你到底需要多少台 Kafka 服务器来完成这个业务呢？</p>
<p>千兆网络下，单台机器，假设kafka占用70%的带宽（总要为其他进程保留一些资源），稍等，这只是它能使用的最大带宽资源，你不能让 Kafka 服务器常规性使用这么多资源，故通常要再额外预留出 2&#x2F;3 的资源，即单台服务器使用带宽 700Mb &#x2F; 3 ≈ 240Mbps。有了 240Mbps，我们就可以计算 1 小时内处理 1TB 数据所需的服务器数量了。根据这个目标，我们每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台。</p>
<h2 id="重要的集群参数配置"><a href="#重要的集群参数配置" class="headerlink" title="重要的集群参数配置"></a>重要的集群参数配置</h2><p>参数配置分为四个方面：</p>
<ul>
<li>broker端参数配置</li>
<li>topic的参数配置</li>
<li>JVM的参数配置</li>
<li>操作系统的参数配置</li>
</ul>
<h3 id="broker端参数（静态参数）"><a href="#broker端参数（静态参数）" class="headerlink" title="broker端参数（静态参数）"></a>broker端参数（静态参数）</h3><p>静态参数是指修改后需要重启才能生效的参数；</p>
<p>是配置在 kafka安装的这个机器上的。通过静态的配置文件配置的。</p>
<h4 id="存储信息类参数"><a href="#存储信息类参数" class="headerlink" title="存储信息类参数"></a>存储信息类参数</h4><p>表示 Broker 使用哪些磁盘</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>log.dirs</td>
<td>【没有默认值的，必须手动指定】指定Broker需要使用的若干个文件目录路径，可配置多个</td>
</tr>
<tr>
<td>log.dir</td>
<td>【一般不用设置，新版本已经取消了】只能配置一个，用来补充上面参数的</td>
</tr>
</tbody></table>
<h4 id="与ZK相关的参数"><a href="#与ZK相关的参数" class="headerlink" title="与ZK相关的参数"></a>与ZK相关的参数</h4><p>ZK负责协调管理并保存 Kafka 集群的所有元数据信息，比如集群都有哪些 Broker 在运行、创建了哪些 Topic，每个 Topic 都有多少分区以及这些分区的 Leader 副本都在哪些机器上等信息</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>zookeeper.connect</td>
<td>负责协调管理并保存 Kafka 集群的所有元数据信息</td>
</tr>
</tbody></table>
<h4 id="broker连接相关的参数"><a href="#broker连接相关的参数" class="headerlink" title="broker连接相关的参数"></a>broker连接相关的参数</h4><p>表示客户端程序或其他 Broker 如何与该 Broker 进行通信的设置</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>listeners</td>
<td>告诉外部连接需要通过什么协议访问指定主机名和端口开放的kafka服务（用于内网访问）</td>
</tr>
<tr>
<td>Advertised.listeners</td>
<td>表明这组监听器是broker对外发布的（用于外网访问）</td>
</tr>
<tr>
<td>host.name&#x2F;port</td>
<td>这俩参数是过期参数，忘掉</td>
</tr>
</tbody></table>
<h4 id="topic管理的参数"><a href="#topic管理的参数" class="headerlink" title="topic管理的参数"></a>topic管理的参数</h4><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>auto.create.topics.enable</td>
<td>是否允许自动创建topic，<br />建议设置成false；</td>
</tr>
<tr>
<td>unclean.leader.election.enable</td>
<td>是否允许Unclean Leader选举，<br />建议设置为false；<br />kafka的分区有多个副本，并不是所有的副本都有资格竞争Leader，只有保存数据比较多的才有资格；那如果保存数据比较多的副本全都挂了，那还要不要竞选Leader呢？ 就是这个参数控制的；<br />false表示不竞选，后果：分区不可用；<br />true表示竞选；后果：数据不一致；</td>
</tr>
<tr>
<td>auto.leader.rebalance.enable</td>
<td>是否允许定期进行Leader选举；true表示到达一定条件，kafka会自动把leader换了，注意是换掉，而不是选举；即使原来的leaderA运行的好好地，也会给换成leaderB；换leader的代价很大，建议设置为false；</td>
</tr>
</tbody></table>
<h4 id="数据留存方面的参数"><a href="#数据留存方面的参数" class="headerlink" title="数据留存方面的参数"></a>数据留存方面的参数</h4><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>log.retention.{hour|minutes|ms}</td>
<td>控制一条消息被保留多长时间</td>
</tr>
<tr>
<td>log.retention.bytes</td>
<td>Broker为保留消息提供的磁盘容量的大小</td>
</tr>
<tr>
<td>message.max.bytes</td>
<td>控制Broker能够接收的最大的消息大小</td>
</tr>
</tbody></table>
<h3 id="Topic的参数配置"><a href="#Topic的参数配置" class="headerlink" title="Topic的参数配置"></a>Topic的参数配置</h3><p>topic端的参数配置会覆盖broker端的参数配置</p>
<p>Topic 端的参数是在创建Topic的时候，手动设置的。<a href="#%E6%80%8E%E4%B9%88%E4%BF%AE%E6%94%B9topic%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">怎么修改topic的参数配置</a></p>
<h4 id="数据留存方面的参数-1"><a href="#数据留存方面的参数-1" class="headerlink" title="数据留存方面的参数"></a>数据留存方面的参数</h4><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>retention.ms</td>
<td>规定了该topic下数据的保存时长，默认7天，如果配置了，就会覆盖broker端的配置</td>
</tr>
<tr>
<td>retention.bytes</td>
<td>规定了要为该topic预留多少磁盘容量空间</td>
</tr>
<tr>
<td>max.message.bytes</td>
<td>该参数跟 Broker 端的 message.max.bytes 参数的作用是一样的，只不过 max.message.bytes 是作用于某个 topic，而 message.max.bytes 是作用于全局。</td>
</tr>
</tbody></table>
<h4 id="怎么修改topic的参数配置"><a href="#怎么修改topic的参数配置" class="headerlink" title="怎么修改topic的参数配置"></a>怎么修改topic的参数配置</h4><ul>
<li><p>创建topic的时候设置</p>
<ul>
<li><blockquote>
<p>bin&#x2F;kafka-topics.sh –bootstrap-server localhost:9092 –create –topic transaction –partitions 1 –replication-factor 1 –config retention.ms&#x3D;15552000000 –config max.message.bytes&#x3D;5242880</p>
</blockquote>
</li>
</ul>
</li>
<li><p>修改topic的时候设置</p>
<ul>
<li><blockquote>
<p>bin&#x2F;kafka-configs.sh –zookeeper localhost:2181 –entity-type topics –entity-name transaction –alter –add-config max.message.bytes&#x3D;10485760</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="JVM的参数配置"><a href="#JVM的参数配置" class="headerlink" title="JVM的参数配置"></a>JVM的参数配置</h3><p>设置kafka的JVM参数，只需要设置环境变量就可以啦。<a href="#%E6%80%8E%E4%B9%88%E5%AF%B9kafka%E8%AE%BE%E7%BD%AEJVM%E5%8F%82%E6%95%B0">怎么对kafka设置JVM参数</a></p>
<table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>KAFKA_HEAP_OPTS</td>
<td>JVM堆大小，建议设置为6GB，默认的1GB太小了</td>
</tr>
<tr>
<td>KAFKA_JVM_PERFORMANCE_OPTS</td>
<td>指定垃圾回收器<br>在java7下：cpu充足，就用CMS；否则使用ParallelGC<br>在java8下：选择G1</td>
</tr>
</tbody></table>
<h4 id="怎么对kafka设置JVM参数"><a href="#怎么对kafka设置JVM参数" class="headerlink" title="怎么对kafka设置JVM参数"></a>怎么对kafka设置JVM参数</h4><p>指定kafka的环境变量即可</p>
<ul>
<li>KAFKA_HEAP_OPTS：指定堆大小</li>
<li>KAFKA_JVM_PERFORMANCE_OPTS：指定垃圾回收器</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
$<span class="token operator">></span> <span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span>--Xms6g  <span class="token parameter variable">--Xmx6g</span>
$<span class="token operator">></span> <span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_JVM_PERFORMANCE_OPTS</span><span class="token operator">=</span> <span class="token parameter variable">-server</span> <span class="token parameter variable">-XX:+UseG1GC</span> <span class="token parameter variable">-XX:MaxGCPauseMillis</span><span class="token operator">=</span><span class="token number">20</span> <span class="token parameter variable">-XX:InitiatingHeapOccupancyPercent</span><span class="token operator">=</span><span class="token number">35</span> <span class="token parameter variable">-XX:+ExplicitGCInvokesConcurrent</span> <span class="token parameter variable">-Djava.awt.headless</span><span class="token operator">=</span>true
$<span class="token operator">></span> bin/kafka-server-start.sh config/server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>



<h3 id="操作系统的参数配置"><a href="#操作系统的参数配置" class="headerlink" title="操作系统的参数配置"></a>操作系统的参数配置</h3><table>
<thead>
<tr>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>文件描述符限制</td>
<td>ulimit -n；其实设置这个参数不重要，但是不设置后果很严重，会看到too many open file 的报错；</td>
</tr>
<tr>
<td>文件系统类型</td>
<td>文件系统类型（ext3，ext4，XFS），XFS的性能强于ext4，ZFS的性能强于XFS（但技术比较新，使用很少）</td>
</tr>
<tr>
<td>Swappiness</td>
<td>网上很多文章都提到设置其为 0，将 swap 完全禁掉以防止 Kafka 进程使用 swap 空间。我个人反倒觉得还是不要设置成 0 比较好，我们可以设置成一个较小的值。为什么呢？因为一旦设置成 0，当物理内存耗尽时，操作系统会触发 OOM killer 这个组件，它会随机挑选一个进程然后 kill 掉，即根本不给用户任何的预警。但如果设置成一个比较小的值，当开始使用 swap 空间时，你至少能够观测到 Broker 性能开始出现急剧下降，从而给你进一步调优和诊断问题的时间。基于这个考虑，我个人建议将 swappniess 配置成一个接近 0 但不为 0 的值，比如 1。</td>
</tr>
<tr>
<td>提交时间（系统的刷盘时间）</td>
<td>提交时间或者说是 Flush 落盘时间。向 Kafka 发送数据并不是真要等数据被写入磁盘才会认为成功，而是只要数据被写入到操作系统的页缓存（Page Cache）上就可以了，随后操作系统根据 LRU 算法会定期将页缓存上的“脏”数据落盘到物理磁盘上。这个定期就是由提交时间来确定的，默认是 5 秒。一般情况下我们会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。当然你可能会有这样的疑问：如果在页缓存中的数据在写入到磁盘前机器宕机了，那岂不是数据就丢失了。的确，这种情况数据确实就丢失了，但鉴于 Kafka 在软件层面已经提供了多副本的冗余机制，因此这里稍微拉大提交间隔去换取性能还是一个合理的做法。</td>
</tr>
</tbody></table>
<h2 id="分区机制"><a href="#分区机制" class="headerlink" title="分区机制"></a>分区机制</h2><p>对于那种大批量机器组成的集群环境，每分钟产生的日志量都能以 GB 数，因此如何将这么大的数据量均匀地分配到 Kafka 的各个 Broker 上，就成为一个非常重要的问题。</p>
<p>我们知道 kafka 的数据，是以 Topic 为概念进行存储的，而<code>topic</code>是一个逻辑概念，真正存放数据的是<code>topic</code>下的<code>partition</code>；<code>partition</code>是物理概念；</p>
<p>一个消息只会保存在一个<code>topic</code>下的一个<code>partition</code>中，不会保存在多个<code>partition</code>中（<code>Replica</code>除外）</p>
<p>那么，为了保证大数据量的均匀分布，其实就是保证一个<code>topic</code>下的数据量均匀的分散在各个<code>partition</code>中；</p>
<p>那么问题来了？</p>
<h3 id="为什么要分区"><a href="#为什么要分区" class="headerlink" title="为什么要分区"></a>为什么要分区</h3><p>为什么要<code>Partiton</code>，为什么<code>kafka</code>不直接存储数据，而是要分区存储？为什么要使用<code>Partiton</code>，而不是直接使用<code>topic</code>？</p>
<p>分区的目的是为了<strong>负载均衡</strong>；或者说分区的目的是为了<strong>提高系统的可伸缩性</strong>；</p>
<ul>
<li>负载均衡<ul>
<li>如果没有分区，所有的请求全部在一个<code>topic</code>上，请求量大的时候，只对一个磁盘进行大量的读写（分钟<code>GB</code>级别的数据量），可能直接就崩了；</li>
</ul>
</li>
<li>可伸缩性<ul>
<li>顺丰的<code>kafka</code>一般是32分区，这样每一个<code>Partition</code>都可以有一个<code>consumer</code>，提升系统的吞吐量；当数据量增长的时候，可以扩<code>Partition</code>，32-&gt;64；提升系统的可伸缩性；</li>
<li>但是一般不建议直接扩<code>Partition</code>，在顺丰，一般是申请新的<code>topic</code>，然后将消息转发到不同的<code>topic</code>中，变相的实现扩<code>Partition</code>；</li>
<li>因为<code>Partition</code>过多，<code>kafka</code>管理起来很困难，没必要增加不必要的消耗；</li>
</ul>
</li>
<li><code>Partition</code>可以实现业务上的功能（消息的顺序问题）</li>
</ul>
<p>以上说了<code>Partiton</code>存在的必要性</p>
<p>那么既然存在<code>Partiton</code>，怎么保证每个<code>Partiton</code>的数据量的均匀呢，避免数据倾斜？这就涉及到分区的策略</p>
<h3 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h3><p>分区策略：就是决定消息被发送到哪个分区</p>
<table>
<thead>
<tr>
<th>分区策略</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>轮训</td>
<td>没有指定<code>partitioner.class</code>这个配置的时候，在没有指定key的时候（消息键保留策略），轮训策略是兜底的</td>
</tr>
<tr>
<td>随机</td>
<td>使用的很少了，已经被废弃了</td>
</tr>
<tr>
<td>自定义</td>
<td>需要显示的配置<code>partitioner.class</code>这个配置，同时需要编写代码；</td>
</tr>
<tr>
<td>按消息键保留策略</td>
<td>按照key的顺序进行存放</td>
</tr>
</tbody></table>
<p>默认分区策略：如果指定了key，按照key分发；没有指定key，按照轮训；</p>
<h3 id="怎么设置分区策略"><a href="#怎么设置分区策略" class="headerlink" title="怎么设置分区策略"></a>怎么设置分区策略</h3><p><strong>轮训</strong></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">不需要配置，默认的就是这个。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>



<p><strong>随机</strong></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">></span></span> partitions <span class="token operator">=</span> cluster<span class="token punctuation">.</span><span class="token function">partitionsForTopic</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">return</span> <span class="token class-name">ThreadLocalRandom</span><span class="token punctuation">.</span><span class="token function">current</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">nextInt</span><span class="token punctuation">(</span>partitions<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<p><strong>按消息键保序策略</strong></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">></span></span> partitions <span class="token operator">=</span> cluster<span class="token punctuation">.</span><span class="token function">partitionsForTopic</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">return</span> <span class="token class-name">Math</span><span class="token punctuation">.</span><span class="token function">abs</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span><span class="token function">hashCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">%</span> partitions<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<p><strong>自定义</strong></p>
<p>比如我想实现：根据 <code>Broker</code> 所在的 <code>IP</code> 地址判断是南方还是北方，实现定制化的分区策略</p>
<ul>
<li>编写一个具体的类实现<code>org.apache.kafka.clients.producer.Partitioner</code>接口</li>
<li>实现其中的两个方法：<code>partition()</code>和<code>close()</code></li>
<li>显式地配置生产者端的参数<code>partitioner.class</code>为你自己实现类的 <code>Full Qualified Name</code></li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">PartitionInfo</span><span class="token punctuation">></span></span> partitions <span class="token operator">=</span> cluster<span class="token punctuation">.</span><span class="token function">partitionsForTopic</span><span class="token punctuation">(</span>topic<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">return</span> partitions<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>p <span class="token operator">-></span> <span class="token function">isSouth</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span><span class="token function">leader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">host</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">PartitionInfo</span><span class="token operator">::</span><span class="token function">partition</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">findAny</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>



<h2 id="消息压缩（消息格式）"><a href="#消息压缩（消息格式）" class="headerlink" title="消息压缩（消息格式）"></a>消息压缩（消息格式）</h2><h3 id="为什么要压缩？"><a href="#为什么要压缩？" class="headerlink" title="为什么要压缩？"></a>为什么要压缩？</h3><p>说起压缩<code>compression</code>，我相信你一定不会感到陌生。它秉承了用时间去换空间的经典 <code>trade-off</code> 思想，具体来说就是用 CPU 时间去换磁盘空间或网络 I&#x2F;O 传输量，希望以较小的 CPU 开销带来更少的磁盘占用或更少的网络 I&#x2F;O 传输。在 <code>Kafka</code> 中，压缩也是用来做这件事的。</p>
<h3 id="kafka的消息格式"><a href="#kafka的消息格式" class="headerlink" title="kafka的消息格式"></a>kafka的消息格式</h3><p>kafka有两大类消息格式，一类是在<code>0.11.0.0</code>版本之前的消息格式（称作V1版本），一个是<code>0.11.0.0</code>版本之后的格式（称作V2版本）；</p>
<p>不管是哪个版本，kafka消息层次都是分为两层：</p>
<table>
<thead>
<tr>
<th>V1版本</th>
<th>V2版本</th>
</tr>
</thead>
<tbody><tr>
<td>消息集合（message set） + 消息（message）</td>
<td>消息集合（record batch） + 消息（record）</td>
</tr>
</tbody></table>
<p>一个消息集合中包含若干个日志项<code>record item</code>，日志项<code>record item</code>才是真正封装消息的地方；（注意这里不要和日志段（<code>Log Segment</code>）混为一谈）</p>
<p>V2版本对V1版本进行了优化，将日志项<code>record item</code>中一些通用的字段抽出来，放在了消息集合中；</p>
<p>V2版本对V1版本还有一个关于压缩方面的优化</p>
<h3 id="怎么压缩"><a href="#怎么压缩" class="headerlink" title="怎么压缩"></a>怎么压缩</h3><p>V2 版本对 V1 版本还有一个关于压缩方面的优化</p>
<p>V1 版本：是把多条消息进行压缩，然后将压缩后的内容放在外层消息的消息体字段中； </p>
<p>V2 版本：是对整个消息集合进行压缩，显然V2版本的压缩效率应该更高；</p>
<p>压缩使用到的是压缩算法：<a href="#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%89%E6%8B%A9">压缩算法的选择</a></p>
<h3 id="何时压缩"><a href="#何时压缩" class="headerlink" title="何时压缩"></a>何时压缩</h3><p>在 <code>kafka</code> 中，压缩可能发生在：<code>Producer</code>端和<code>Broker</code>端</p>
<ul>
<li><p><code>Producer</code>端【一般都是<code>Producer</code>端做压缩】</p>
<ul>
<li>在<code>Producer</code>程序中添加一个配置：<code>compression.type</code> 参数</li>
<li>compression.type&#x3D;gzip 表示开启gzip压缩</li>
</ul>
</li>
<li><p><code>Broker</code>端</p>
<ul>
<li>一般<code>Broker</code>端不会对<code>Producer</code>发出来的消息进行修改；</li>
<li>有两个例外情况，会让<code>Broker</code>对消息重新压缩<ul>
<li><code>Broker</code>端和<code>Producer</code>端指定的消息压缩算法不一致（不一致的时候，<code>broker</code>端会对<code>producer</code>端发出来的消息解压然后重新压缩）</li>
<li><code>Broker</code>端发生了消息格式转换：新老版本消息格式（V1版本和V2版本）兼容的问题</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="何时解压缩"><a href="#何时解压缩" class="headerlink" title="何时解压缩"></a>何时解压缩</h3><ul>
<li><code>consumer</code>端消费到消息的时候，进行解压缩<ul>
<li>解压缩的时候，压缩算法是在消息中，用一个字段标识的，所以<code>consumer</code>可以拿到消息之后在解压缩</li>
</ul>
</li>
<li><code>broker</code>端收到<code>producer</code>发出的消息之后，也会解压缩一次，进行消息的校验；</li>
</ul>
<h3 id="压缩的时机"><a href="#压缩的时机" class="headerlink" title="压缩的时机"></a>压缩的时机</h3><p>记住这句话：<code>Producer</code>端压缩，<code>Broker</code>端保持，<code>Consumer</code>端解压缩</p>
<h3 id="压缩算法的选择"><a href="#压缩算法的选择" class="headerlink" title="压缩算法的选择"></a>压缩算法的选择</h3><p>一般看两个指标：压缩比 和 压缩&#x2F;解压缩的吞吐量</p>
<p>GZIP</p>
<p>Snappy</p>
<p>LZ4</p>
<p>zstd</p>
<h2 id="消息丢失"><a href="#消息丢失" class="headerlink" title="消息丢失"></a>消息丢失</h2><p><code>kafka</code>只对 已提交成功 的消息做有限度的持久化保证；</p>
<h3 id="什么是消息丢失"><a href="#什么是消息丢失" class="headerlink" title="什么是消息丢失"></a>什么是消息丢失</h3><p>对于<code>Producer</code>来说：消息发不出去，就是丢失；</p>
<p>对于<code>Consumer</code>来说：消息消费不到，就是丢失；</p>
<p>对于<code>Broker</code>来说：不存在丢失，<code>Broker</code>会对 已提交成功 的消息，做有限度的持久化；</p>
<h3 id="什么时候会消息丢失"><a href="#什么时候会消息丢失" class="headerlink" title="什么时候会消息丢失"></a>什么时候会消息丢失</h3><ul>
<li><code>Producer</code>丢失消息<ul>
<li><code>producer.send(msg) </code>因为是异步，<code>fire and forget</code> 所以可能会丢消息</li>
<li>网络抖动、消息不合法被<code>broker</code>拒收（比如：消息体太大）等都会导致消息发送不成功</li>
</ul>
</li>
<li><code>Consumer</code>丢失消息<ul>
<li>消费的消息不存在了。一般只有先提交<code>offset</code>在消费的场景下会发生；</li>
<li>多线程处理消息的时候，某一个线程消费失败了，但是<code>offset</code>自动提交了；</li>
</ul>
</li>
</ul>
<h3 id="怎么保证消息不丢失"><a href="#怎么保证消息不丢失" class="headerlink" title="怎么保证消息不丢失"></a>怎么保证消息不丢失</h3><p>上面几种丢失消息的场景，怎么避免？</p>
<ul>
<li>【<code>Producer</code>端】：不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>。一定要使用带有回调通知的 <code>send </code>方法。</li>
<li>【<code>Producer</code>端】：设置 <code>acks</code> &#x3D; <code>all</code>。是个动态值（如果原来有<code>3</code>个<code>Replica</code>，就要写入<code>3</code>个，如果有<code>1</code>个挂了，那就只需要写入<code>2</code>个），表明所有<code>Replica</code>都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。</li>
<li>【<code>Producer</code>端】：设置 <code>retries</code> 为一个较大的值。 表示<code>Producer </code>自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，这里开启自动重试，避免消息丢失。（重试会导致消息乱序吗：会）</li>
<li>【Broker端】：设置 <code>unclean.leader.election.enable</code> &#x3D; <code>false</code>。它控制的是哪些 <code>Replica </code>有资格竞选分区的 <code>Leader</code>。如果一个 <code>Replica </code> 落后原先的 <code>Leader </code>太多，就不要让它竞选，即不允许这种情况的发生。</li>
<li>【Broker端】：设置<code> replication.factor</code> &gt;&#x3D; <code>3</code>。表示某个分区的<code>Replica</code>总数，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余</li>
<li>【Broker端】：设置 <code>min.insync.replicas</code> &gt; 1。表示至少写入多少个<code>Replica</code>才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。</li>
<li>【Broker端】：确保<code> replication.factor</code> &gt; <code>min.insync.replicas</code>。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 <code>replication.factor</code> &#x3D; <code>min.insync.replicas</code> + <code>1</code>。</li>
<li>【<code>Consumer</code>端】：设置<code>enable.auto.commit</code>&#x3D; <code>false</code>，采用手动提交位移的方式。就像前面说的，这对于单 <code>Consumer </code>多线程处理的场景而言是至关重要的。</li>
</ul>
<p>举个例子：</p>
<p>比如<code>Replica</code>&#x3D;<code>3</code>，设置<code>min.insync.replicas</code>&#x3D;<code>2</code>，<code>acks</code>&#x3D;<code>all</code></p>
<p>如果<code>Replica</code>都正常工作：此时<code>acks</code>&#x3D;<code>all</code>的约束就是写入<code>3</code>个<code>Replica</code>，才算提交成功，此时满足<code>min.insync.replicas</code>&#x3D;<code>2</code>约束。</p>
<p>如果<code>Replica</code>挂了<code>1</code>个，此时<code>acks</code>&#x3D;<code>all</code>的约束就是写入<code>2</code>个<code>Replica</code>即可，此时满足<code>min.insync.replicas</code>&#x3D;<code>2</code>约束。</p>
<p>如果<code>Replica</code>挂了<code>2</code>个，此时<code>acks</code>&#x3D;<code>all</code>的约束就是写入<code>1</code>个<code>Replica</code>即可，此时不满足<code>min.insync.replicas</code>&#x3D;<code>2</code>这个下限约束，写入失败。</p>
<p>补充：</p>
<blockquote>
<p>设置 ack &#x3D; all，其实就是需要保证 ISR 集合中所有的 Replica 都写入成功才能返回</p>
</blockquote>
<p>公司的生产者的设置</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">KafkaProducer24</span><span class="token punctuation">(</span><span class="token class-name">String</span> brokers<span class="token punctuation">,</span> <span class="token class-name">ProduceOptionalConfig</span> extraConfig<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>extraConfig <span class="token operator">=</span> extraConfig <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">?</span> <span class="token class-name">ProduceOptionalConfig</span><span class="token punctuation">.</span>defaultConfig <span class="token operator">:</span> extraConfig<span class="token punctuation">;</span>
    <span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> brokers<span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"默认是Leader Replica收到就行"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"request.timeout.ms"</span><span class="token punctuation">,</span> <span class="token string">"默认是30000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"compression.type"</span><span class="token punctuation">,</span> <span class="token string">"snappy"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token string">"默认是16384"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token string">"默认是5"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>





<h2 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h2><p>Kafka 拦截器自<code> 0.10.0.0</code> 版本被引入后并未得到太多的实际应用，我也从未在任何 Kafka 技术峰会上看到有公司分享其使用拦截器的成功案例。</p>
<p>拦截器是一个小众功能。</p>
<p>Kafka 拦截器分为生产者拦截器和消费者拦截器</p>
<h3 id="生产者拦截器"><a href="#生产者拦截器" class="headerlink" title="生产者拦截器"></a>生产者拦截器</h3><p>开发：实现<code>org.apache.kafka.clients.producer.ProducerInterceptor</code>这个接口，这个接口有俩方法</p>
<ul>
<li><code>onSend</code>：消息真正发给broker之前</li>
<li><code>onAcknowledgement</code>：消息提交成功之后，在<code>callback</code>之前</li>
</ul>
<h3 id="消费者拦截器"><a href="#消费者拦截器" class="headerlink" title="消费者拦截器"></a>消费者拦截器</h3><p>开发：实现<code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code>这个接口，这个接口有俩方法</p>
<ul>
<li><code>onConsume</code>：在消费者真正处理消息之前</li>
<li><code>onCommit</code>：消费者处理完消息，提交offset之后</li>
</ul>
<h3 id="配置拦截器"><a href="#配置拦截器" class="headerlink" title="配置拦截器"></a>配置拦截器</h3><p>拦截器开发完成了，怎么让它生效呢？</p>
<p>当前 Kafka 拦截器的设置方法是通过参数配置完成的</p>
<p>生产者和消费者两端有一个相同的参数，名字叫 interceptor.classes，它指定的是一组类的列表</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> interceptors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 拦截器1</span>
interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 拦截器2</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">INTERCEPTOR_CLASSES_CONFIG</span><span class="token punctuation">,</span> interceptors<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="生产者与TCP连接"><a href="#生产者与TCP连接" class="headerlink" title="生产者与TCP连接"></a>生产者与TCP连接</h2><h3 id="为什么采用TCP作为底层传输协议"><a href="#为什么采用TCP作为底层传输协议" class="headerlink" title="为什么采用TCP作为底层传输协议"></a>为什么采用TCP作为底层传输协议</h3><p>TCP 拥有一些高级功能，如多路复用请求和同时轮询多个连接的能力。</p>
<p>多路复用请求：multiplexing request，是将两个或多个数据合并到底层—物理连接中的过程。TCP 的多路复用请求会在一条物理连接上创建若干个虚拟连接，每个虚拟连接负责流转各自对应的数据流。严格讲：TCP 并不能多路复用，只是提供可靠的消息交付语义保证，如自动重传丢失的报文。</p>
<h3 id="生产者是什么时候创建TCP连接的"><a href="#生产者是什么时候创建TCP连接的" class="headerlink" title="生产者是什么时候创建TCP连接的"></a>生产者是什么时候创建TCP连接的</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“参数<span class="token number">1</span>”<span class="token punctuation">,</span> “参数<span class="token number">1</span>的值”<span class="token punctuation">)</span>；
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“参数<span class="token number">2</span>”<span class="token punctuation">,</span> “参数<span class="token number">2</span>的值”<span class="token punctuation">)</span>；
……
<span class="token keyword">try</span> <span class="token punctuation">(</span><span class="token class-name">Producer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>……<span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token punctuation">)</span><span class="token punctuation">;</span>
  ……
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>针对上面的代码，能创建TCP连接的只有两个地方，一是 Producer 实例化的时候；一是 producer.send 的时候；</p>
<ul>
<li><strong>Kafka 是在 Producer 实例化的时候与 Broker 建立的 TCP 连接</strong></li>
<li>所以，当 producer.send 的时候，其实已经有TCP连接了</li>
</ul>
<p>扩展：除了在 Producer 实例化的时候与 Broker 建立的 TCP 连接之外，还有没有其他情况？</p>
<ul>
<li>有，有两个情况，也会创建TCP连接</li>
<li><strong>元数据更新时，会与元数据中没有连接的 Broker 建立 TCP 连接；</strong><ul>
<li>每隔5分钟， Producer 会定期从 Broker 中获取元数据信息</li>
<li>Producer 尝试给一个不存在的 Topic 发送消息时，Broker 会说这个 Topic 不存在，然后 Producer 会请求 Broker 更新元数据信息</li>
</ul>
</li>
<li><strong>在消息发送时，如果 Producer 发现与要发送消息的 Topic 所在的 Broker 没有 TCP 连接，就会创建连接；</strong></li>
</ul>
<h3 id="是怎么创建TCP连接的"><a href="#是怎么创建TCP连接的" class="headerlink" title="是怎么创建TCP连接的"></a>是怎么创建TCP连接的</h3><p>在创建 KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的TCP连接。</p>
<p>Broker有1000个，bootstrap.servers 要配置1000个嘛？ 不需要，因为 Producer 一旦连接到集群中的任一台 Broker，就能拿到整个集群的 Broker 信息。</p>
<h3 id="TCP连接是什么时候被关闭的"><a href="#TCP连接是什么时候被关闭的" class="headerlink" title="TCP连接是什么时候被关闭的"></a>TCP连接是什么时候被关闭的</h3><ul>
<li>用户主动关闭，调用 producer.close</li>
<li>Kafka自动关闭（虽然是producer端设置的参数，但实际上，是broker关闭的TCP连接）：与 Producer 端参数 connections.max.idle.ms 的值有关。默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭。用户可以在 Producer 端设置 connections.max.idle.ms&#x3D;-1 禁掉这种机制。一旦被设置成 -1，TCP 连接将成为永久长连接。</li>
</ul>
<h3 id="会存在的一些问题"><a href="#会存在的一些问题" class="headerlink" title="会存在的一些问题"></a>会存在的一些问题</h3><ul>
<li>producer每5分钟获取一些元数据，然后与元数据中没有连接的broker建立TCP连接，然后9分钟后，broker会中断空闲的连接，然后5分钟后，在此建立连接；9分钟后，再次中断连接；</li>
</ul>
<h2 id="消费者与TCP连接"><a href="#消费者与TCP连接" class="headerlink" title="消费者与TCP连接"></a>消费者与TCP连接</h2><h3 id="消费者是什么时候创建TCP连接的"><a href="#消费者是什么时候创建TCP连接的" class="headerlink" title="消费者是什么时候创建TCP连接的"></a>消费者是什么时候创建TCP连接的</h3><ul>
<li>生产者是在new KakfaProducer的时候，后台开启一个Sender的线程用来创建TCP连接的；</li>
<li>消费者<strong>不是</strong>在实例化的时候创建的，而是在开始消费消息的时候（consumer.poll）才主动创建TCP连接，准确的说有三个时机<ul>
<li>发起 FindCoordinator 请求时（连接的brokerId是-1，因为不知道连哪一个）</li>
<li>连接协调者的时候（连接的brokerId是 <code>Interger.Max - 协调者所在broker的Id号</code> ，为什么这么设计，为了防止连接重用）</li>
<li>真正消费消息的时候（连接某个topic的某个分区的leader副本所在的broker）</li>
</ul>
</li>
</ul>
<h3 id="创建多少个TCP连接"><a href="#创建多少个TCP连接" class="headerlink" title="创建多少个TCP连接"></a>创建多少个TCP连接</h3><p>会创建三类TCP连接</p>
<ul>
<li>FindCoordinator 请求与任意一个 Broker 的 TCP 连接</li>
<li>与 Coordinator 的连接，此时消费者才能真正的开始工作</li>
<li>与 Partition 所在leader副本的TCP连接，拉取消息，真正开始处理</li>
</ul>
<p>其中第一类（FIndCoordinator请求与任意一个Broker的连接）会在消费者真正开始处理消息的时候，也就是后面两类TCP连接建立好之后，第一类连接会被关闭掉；</p>
<h3 id="消费者是什么时候关闭TCP连接的"><a href="#消费者是什么时候关闭TCP连接的" class="headerlink" title="消费者是什么时候关闭TCP连接的"></a>消费者是什么时候关闭TCP连接的</h3><p>上面说的三类连接，其中第一类连接会在二，三类连接创建好之后，被关闭掉；</p>
<p>二，三类连接的关闭场景有两种：</p>
<ul>
<li>主动关闭，这个不说了</li>
<li>kafka自动关闭，由 消费者端参数connection.max.idle.ms控制。当超过指定时间，该消费者没有消息消费时，就会被关闭连接（但是如果我们的消费逻辑是while循环的情况，则永远不会被关闭，因为一直与broker保持通信，实现了“长链接”的效果）</li>
</ul>
<h3 id="可能存在的问题"><a href="#可能存在的问题" class="headerlink" title="可能存在的问题"></a>可能存在的问题</h3><p>第一类 TCP 连接仅仅是为了首次获取元数据而创建的，后面就会被废弃掉。最根本的原因是，消费者在启动时还不知道 Kafka 集群的信息，只能使用“-1” 去注册，即使消费者获取了真实的 Broker ID，它依旧无法区分这个“-1”对应的是哪台 Broker，因此也就无法重用这个 Socket 连接，只能再重新创建一个新的连接。</p>
<p>为什么会出现这种情况呢？主要是因为目前 Kafka 仅仅使用 ID 这一个维度的数据来表征 Socket 连接信息。这点信息明显不足以确定连接的是哪台 Broker，也许在未来，社区应该考虑使用 &lt; 主机名、端口、ID&gt; 三元组的方式来定位 Socket 资源，这样或许能够让消费者程序少创建一些 TCP 连接。</p>
<p>也许你会问，反正 Kafka 有定时关闭机制，这算多大点事呢？其实，在实际场景中，我见过很多将 connection.max.idle.ms 设置成 -1，即禁用定时关闭的案例，如果是这样的话，这些 TCP 连接将不会被定期清除，只会成为永久的“僵尸”连接。基于这个原因，社区应该考虑更好的解决方案。</p>
<h2 id="幂等和事务生产者"><a href="#幂等和事务生产者" class="headerlink" title="幂等和事务生产者"></a>幂等和事务生产者</h2><h3 id="消息交付可靠性"><a href="#消息交付可靠性" class="headerlink" title="消息交付可靠性"></a>消息交付可靠性</h3><p>所谓的消息交付可靠性，是指<code>kafka</code>对<code>Producer</code>和<code>Consumer</code>要处理的消息，提供什么样的承诺：</p>
<ul>
<li><p><code>最多一次</code>：消息只会被发送一次，可能会丢失，绝不会重复</p>
</li>
<li><p><code>至少一次</code>（默认）：发送消息的时候，至少要有一次broker明确告知已经提交的callback，消息可能重复，但不会丢失</p>
</li>
<li><p><code>精确一次</code>：消息不会丢失，也不会重复</p>
</li>
</ul>
<h3 id="幂等和事务的概念"><a href="#幂等和事务的概念" class="headerlink" title="幂等和事务的概念"></a>幂等和事务的概念</h3><p>略</p>
<h3 id="幂等生产者"><a href="#幂等生产者" class="headerlink" title="幂等生产者"></a>幂等生产者</h3><p>在 Kafka 中，<code>Producer </code>默认不是幂等性的，但我们可以创建幂等性 <code>Producer</code>。</p>
<p>在没有幂等之前，<code>Producer</code>向一个<code>Partition</code>发送消息，可能会出现同一条消息被多次发送的情况，导致消息重复</p>
<p>在有了幂等之后，<code>Producer</code>向一个<code>Partition</code>发送消息，发送一次和发送多次，由于幂等存在，在当前这一个<code>Partition</code>内消息不会重复</p>
<h4 id="幂等生产者的使用方式"><a href="#幂等生产者的使用方式" class="headerlink" title="幂等生产者的使用方式"></a>幂等生产者的使用方式</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“enable<span class="token punctuation">.</span>idempotence”<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
或
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span><span class="token constant">ENABLE_IDEMPOTENCE_CONFIG</span>， <span class="token boolean">true</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>设置 <code>enable.idempotence = true</code> 后，<code>Producer </code>自动升级成幂等性 <code>Producer</code></p>
<p>如果把 <code>enable.idempotence = true</code> ，则一定要设置<code>ack = all</code>，否则会报错：Must set acks to all in order to use the idempotent producer. Otherwise we cannot guarantee idempotence</p>
<p>其他所有的代码逻辑都不需要改变。</p>
<p>Kafka 自动做消息的重复去重</p>
<p>公司并没有使用幂等生产者，以下是公司的代码</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token class-name">KafkaProducer24</span><span class="token punctuation">(</span><span class="token class-name">String</span> brokers<span class="token punctuation">,</span> <span class="token class-name">ProduceOptionalConfig</span> extraConfig<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>extraConfig <span class="token operator">=</span> extraConfig <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">?</span> <span class="token class-name">ProduceOptionalConfig</span><span class="token punctuation">.</span>defaultConfig <span class="token operator">:</span> extraConfig<span class="token punctuation">;</span>
    <span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> brokers<span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"默认是Leader Replica收到就行"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"request.timeout.ms"</span><span class="token punctuation">,</span> <span class="token string">"默认是30000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"compression.type"</span><span class="token punctuation">,</span> <span class="token string">"snappy"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token string">"默认是16384"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token string">"默认是5"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>





<h4 id="幂等生产者的实现原理"><a href="#幂等生产者的实现原理" class="headerlink" title="幂等生产者的实现原理"></a>幂等生产者的实现原理</h4><ul>
<li>Producer 在每次启动后，都会向 Broker 申请一个全局一个唯一的 pid ，用来标识本次会话</li>
<li>V2版本的消息格式增加了 sequence number 字段， producer 每发一批消息， seq 就加1</li>
<li>broker 在内存中会维护 &lt;pid, topic, partition, seq&gt; 映射，收到消息后检查 seq ，如果：<ul>
<li>new_seq &#x3D; old_seq + 1 ：正常消息</li>
<li>new_seq &lt;&#x3D; old_seq ：重复消息</li>
<li>new_seq &gt; old_seq + 1 ： 消息丢失</li>
</ul>
</li>
</ul>
<h4 id="幂等生产者的作用范围"><a href="#幂等生产者的作用范围" class="headerlink" title="幂等生产者的作用范围"></a>幂等生产者的作用范围</h4><p>只能实现单Session上的幂等性</p>
<ul>
<li>因为<code>Producer</code>的每次重启，都会向<code>Broker</code>申请一个新的全局唯一的<code>pid</code>，用来标识本次会话</li>
<li><code>Producer</code>在不同<code>Session</code>上的<code>pid</code>不一样，是幂等不能跨<code>Session</code>的主要原因。</li>
</ul>
<p>只能保证单分区上的幂等性</p>
<ul>
<li>因为<code>Broker</code>端维护的映射是<code>Partiton</code>粒度的，所以只能保证单分区上的幂等性</li>
</ul>
<p>那么你可能会问，如果我想实现多分区以及多会话上的消息无重复，应该怎么做呢？答案就是事务（transaction）或者依赖事务型 Producer。</p>
<h3 id="事务生产者"><a href="#事务生产者" class="headerlink" title="事务生产者"></a>事务生产者</h3><p>如果我想实现多分区以及多会话上的消息无重复，应该怎么做呢？答案就是事务（transaction）或者依赖事务型 Producer。</p>
<p>这也是幂等性 Producer 和事务型 Producer 的最大区别！</p>
<p>在 Kafka 中，<code>Producer </code>默认不是幂等性的，同时默认也不是事务的。</p>
<p>Kafka 自 0.11 版本开始也提供了对事务的支持，它能保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息。</p>
<h4 id="事务生产者的使用方式"><a href="#事务生产者的使用方式" class="headerlink" title="事务生产者的使用方式"></a>事务生产者的使用方式</h4><p>要想使用kafka的事务，需要同时设置<code>Producer</code>和<code>Consumer</code></p>
<p><strong>设置Producer</strong></p>
<p>设置事务型 Producer 的方法也很简单，满足两个要求即可：</p>
<ul>
<li>和幂等性 Producer 一样，开启 <code>enable.idempotence = true</code></li>
<li>设置 Producer 端参数<code> transactional.id</code>。最好为其设置一个有意义的名字。</li>
<li>在发送消息的时候，需要显示的开启<code>beginTransaction</code>和提交<code>commitTransaction</code>事务</li>
<li>消息1和消息2，要么全部成功，要么全部失败</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//创建事务生产者</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“enable<span class="token punctuation">.</span>idempotence”<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>“transactional<span class="token punctuation">.</span>id”<span class="token punctuation">,</span> <span class="token string">"my-transcation-id-zs"</span><span class="token punctuation">)</span>


producer<span class="token punctuation">.</span><span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//初始化事务</span>
<span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
    producer<span class="token punctuation">.</span><span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//开启事务</span>
    producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record1<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//发送消息1</span>
    producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record2<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//发送消息2</span>
    producer<span class="token punctuation">.</span><span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//提交事务</span>
<span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">KafkaException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    producer<span class="token punctuation">.</span><span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//终止事务</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p><strong>设置Consumer</strong></p>
<ul>
<li>为什么要设置，因为事务型<code>Producer</code>即使发送失败了，也会写到kakfa日志中，会被<code>Consumer</code>消费到；</li>
<li>设置<code>Consumer</code>的 <code>isolation.level</code>参数<ul>
<li><code>read_uncommitted</code>：读未提交，这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。</li>
<li><code>read_committed</code>：读已提交，表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然了，它也能看到非事务型 Producer 写入的所有消息。</li>
</ul>
</li>
</ul>
<h4 id="事务生产者的实现原理"><a href="#事务生产者的实现原理" class="headerlink" title="事务生产者的实现原理"></a>事务生产者的实现原理</h4><p>待补充</p>
<h2 id="消费者组和独立消费者"><a href="#消费者组和独立消费者" class="headerlink" title="消费者组和独立消费者"></a>消费者组和独立消费者</h2><p>Kafka 为了实现点对点（同一个消息只能被下游的一个 Consumer 消费），使用了<code>Consumer Group</code>的概念；</p>
<p>那么什么是<code>Consumer Group</code>呢，我们具体看一下</p>
<p><code>Consumer Group</code>：多个 Consumer 实例组成一组消费某一个 Topic，这个 Topic 下的一条消息只能被组中的一个 Consumer 实例消费；</p>
<h3 id="什么是消费者组"><a href="#什么是消费者组" class="headerlink" title="什么是消费者组"></a>什么是消费者组</h3><p><code>Consumer Group</code> 是 Kafka 提供的可扩展且具有容错性的消费者机制。</p>
<p>组内有多个消费者实例（Consumer Instance），它们共享一个公共的 Group ID。</p>
<p>组内的所有消费者实例（Consumer Instance）一起消费订阅的主题（Subscribed Topics）的所有分区（Partition）。</p>
<p>当然，该 Topic 的每个 Partition 只能由同一个消费者组内的一个 Consumer 实例来消费。</p>
<h3 id="为什么要引入消费者组"><a href="#为什么要引入消费者组" class="headerlink" title="为什么要引入消费者组"></a>为什么要引入消费者组</h3><p>为了提升吞吐量，假设 Topic 的消息的生产速率不变，增加消费者实例，就可以提升吞吐量；</p>
<h3 id="消费者的重平衡"><a href="#消费者的重平衡" class="headerlink" title="消费者的重平衡"></a>消费者的重平衡</h3><p>当组内的某一个消费者实例挂了，kafka会自动重平衡；将这个死亡的消费者实例原先消费的分区，转移给存活的消费者实例；</p>
<p>后面会详细介绍：<a href="#%E9%87%8D%E5%B9%B3%E8%A1%A1">重平衡</a></p>
<h3 id="消费者组的特性是什么"><a href="#消费者组的特性是什么" class="headerlink" title="消费者组的特性是什么"></a>消费者组的特性是什么</h3><ul>
<li><code>Consumer Group</code> 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。</li>
<li><code>Group ID</code> 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。</li>
<li><code>Consumer Group</code>所订阅的 Topic ，该 Topic 下的某<strong>一个</strong> Partition ，只能分配给组内的某<strong>一个</strong> Consumer 实例消费。当然，这个 Partition 也可以被其他的 Group 消费。</li>
</ul>
<h3 id="传统的消息引擎模型"><a href="#传统的消息引擎模型" class="headerlink" title="传统的消息引擎模型"></a>传统的消息引擎模型</h3><ul>
<li>点对点：一个消息只能被一个消费者消费到</li>
<li>发布订阅：一个 Topic 下的消息，可以被订阅该 Topic 的所有消费者都消费到</li>
<li>kafka使用消费者组，实现了两种消息引擎模型； <ul>
<li>如果所有的消费者属于一个消费者组，那就是点对点</li>
<li>如果所有的消费者属于不同的消费者组，那就是发布订阅</li>
</ul>
</li>
</ul>
<h3 id="消费者组的使用方式"><a href="#消费者组的使用方式" class="headerlink" title="消费者组的使用方式"></a>消费者组的使用方式</h3><p>待补充，补充一个代码</p>
<h3 id="消费者组是如何维护offset的"><a href="#消费者组是如何维护offset的" class="headerlink" title="消费者组是如何维护offset的"></a>消费者组是如何维护offset的</h3><p>对于一个单独的消费者来说，offset就是一个数值；</p>
<p>但是对于一个消费者组来说，因为组内有多个消费者，那么消费者组维护offset是通过一个map来维护的，这个map简单的可以理解为是：Map&lt;TopicPartition,Long&gt;</p>
<p>对于老版本的kafka来说，offset是保存在zk中的，但是后来kafka的开发者发现，offset的更新太过于频繁，频繁的封信会拖慢zk的性能，所以在新版本的kafka中，offset是保存在broker内部的一个特殊的topic中的(__consumer_offset)。</p>
<p>下面我们来看看这个特殊的 Topic：位移主题（__consumer_offset）</p>
<h3 id="独立消费者"><a href="#独立消费者" class="headerlink" title="独立消费者"></a>独立消费者</h3><p>在 Kafka 中，消费消息除了使用 消费者组 Consumer Group 外，还有一种消费者会被使用，但是在业务场景中，使用的不多，一般是从在 Kafka 的流处理中。</p>
<p>它是：独立消费者 Standalone Consumer</p>
<p>1、请问Standalone Consumer 的独立消费者一般什么情况会用到 </p>
<ul>
<li>很多流处理框架的Kafka connector都没有使用consumer group，而是直接使用standalone consumer，因为group机制不好把控</li>
</ul>
<p>2、Standalone Consumer 的独立消费者 使用跟普通消费者组有什么区别的。</p>
<ul>
<li>standalone consumer没有rebalance，也没有group提供的负载均衡，你需要自己实现。其他方面（比如位移提交）和group没有太大的不同</li>
</ul>
<p>3、如果使用 Standalone Consumer，是不是也不会发生 rebalance 了？</p>
<ul>
<li>standalone consumer就没有rebalance一说了。 它的特点主要是灵活。虽然社区一直在改进rebalance的性能，但大数据量下consumer group机制依然有很多弊病（比如rebalance太慢等），所以很多大数据框架(Spark &#x2F;Flink)的kafka connector并不使用group机制，而是使用standalone consumer</li>
</ul>
<h2 id="位移和位移主题"><a href="#位移和位移主题" class="headerlink" title="位移和位移主题"></a>位移和位移主题</h2><p>位移在 Kafka 中是一个很重要的概念，分为：消费者位移（Consumer Offset）和分区位移（Offset）：<a href="#%E5%90%8D%E8%AF%8D%E6%9C%AF%E8%AF%AD">名词术语</a></p>
<h3 id="消费者位移和分区位移"><a href="#消费者位移和分区位移" class="headerlink" title="消费者位移和分区位移"></a>消费者位移和分区位移</h3><p>消费者位移（Consumer Offset）：消费者位移是随时变化的，毕竟它是消费者消费进度的指示器嘛。</p>
<p>分区位移（Offset）：表示的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。</p>
<p>举个例子：</p>
<p>一个消息发送到kafka集群，kafka就会给这个消息并一个编号，这个编号就是“分区位移”；而且这个“分区位移”是固定不变的；</p>
<p>当有消费者消费的时候，消费者会记录我自己消费到了哪里，这个就是消费者位移；（消息者位移其实并不是记录在消费者端的，而是记录在zk或者kafka中的）；</p>
<p>分区位移是一个常量，在消息写入到 Partition 中之后，就不变了。所以分区位移没什么好研究的。</p>
<p>我们主要看一看：消费者位移</p>
<h3 id="消费者位移"><a href="#消费者位移" class="headerlink" title="消费者位移"></a>消费者位移</h3><p>之前介绍过，消费者组是怎么维护 消费者位移（Consumer Offset） 的，在低版本中，Consumer Offset 是维护在 ZK 中的，在后续版本中，是记录在 Broker 中的一个特殊的 Topic 中，这个 Topic 叫做：位移主题（__consumer_offset）</p>
<p>__consumer_offsets 在 Kafka 源码中有个更为正式的名字，叫位移主题，即 Offsets Topic。</p>
<h3 id="位移主题"><a href="#位移主题" class="headerlink" title="位移主题"></a>位移主题</h3><h4 id="为什么会有位移主题"><a href="#为什么会有位移主题" class="headerlink" title="为什么会有位移主题"></a>为什么会有位移主题</h4><p>对于老版本的 Kafka 来说，Consumer Offset 是保存在 ZK 中的，但是后来 Kafka 的开发者发现，Consumer Offset 的更新太过于频繁，频繁的更新会拖慢 ZK 的性能，所以在新版本的 Kafka 中，Consumer Offset 是保存在 Broker 内部的一个特殊的 Topic 中的：__consumer_offset</p>
<h4 id="位移主题是什么"><a href="#位移主题是什么" class="headerlink" title="位移主题是什么"></a>位移主题是什么</h4><p>是 Kafka 中的一个内部 Topic</p>
<p>这个 Topic 的主要作用是用来管理 Consumer Offset</p>
<p>Consumer Offset 管理机制其实很简单，就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，发送到 __consumer_offsets 中。</p>
<p>可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。</p>
<h4 id="位移主题什么时候创建"><a href="#位移主题什么时候创建" class="headerlink" title="位移主题什么时候创建"></a>位移主题什么时候创建</h4><p>当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。</p>
<h4 id="位移主题的分区和副本"><a href="#位移主题的分区和副本" class="headerlink" title="位移主题的分区和副本"></a>位移主题的分区和副本</h4><p>我们知道 __consumer_offset 虽然是内部 Topic，但是它仍然是一个 Topic ，既然是 Topic ，那么它的分区数和副本是多少呢？</p>
<ul>
<li>分区数：50；由Broker 端参数 offsets.topic.num.partitions指定</li>
<li>副本数：3；由Broker 端参数 offsets.topic.replication.factor指定</li>
</ul>
<h4 id="位移主题中存了什么"><a href="#位移主题中存了什么" class="headerlink" title="位移主题中存了什么"></a>位移主题中存了什么</h4><p>存了三类消息</p>
<ul>
<li>位移消息：表示当前消费者组消费的位移信息</li>
<li>用于保存 Consumer Group 信息的消息：比较神秘，几乎无法在搜索引擎中搜到。不过，你只需要记住它是用来注册 Consumer Group 的就可以了。</li>
<li>用于删除 Group 过期位移甚至是删除 Group 的消息：tombstone 消息，即墓碑消息，也称 delete mark</li>
</ul>
<p><strong>位移消息</strong></p>
<p>之前说过，Kafka 中有两种消息格式，<a href="#kafka%E7%9A%84%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F">kafka的消息格式</a>，那么位移主题的消息格式，其实是 Kafka 自定义的特殊消息格式。</p>
<p>既然是自定义的消息格式，也就说明：开发者不能随意的向这个主题发送消息，因为一旦你写入的消息不满足 Kafka 规定的格式，那么 Kafka 内部无法成功解析，就会造成 Broker 的崩溃。</p>
<p>那么这个主题存的到底是什么格式的消息呢？</p>
<p>事实上， Kafka 自定义的位移主题消息格式，其实是一个 KV 结构</p>
<p>K：保存 3 部分内容：&lt;Group ID，主题名，分区号&gt;  （即使是单个消费者（Standalone Consumer），也是会有groupid的）</p>
<p>V：Offset</p>
<p><strong>墓碑消息</strong></p>
<p>墓碑消息只出现在源码中而不暴露给你。</p>
<p>它的主要特点是它的消息体是 null，即空消息体。</p>
<p>那么，何时会写入这类消息呢？</p>
<p>一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的 Consumer Offset 数据都已被删除时，Kafka 会向位移主题的对应分区写入 tombstone 消息，表明要彻底删除这个 Consumer Group 的信息。</p>
<h4 id="怎么提交offset到位移主题"><a href="#怎么提交offset到位移主题" class="headerlink" title="怎么提交offset到位移主题"></a>怎么提交offset到位移主题</h4><p>Kafka Consumer 提交 Offset 时会写入  __consumer_offset 这个 Topic</p>
<p>那 Consumer 是怎么提交位移的呢？</p>
<p>目前 Kafka Consumer 提交位移的方式有两种：自动提交位移和手动提交位移。</p>
<h5 id="自动提交位移"><a href="#自动提交位移" class="headerlink" title="自动提交位移"></a>自动提交位移</h5><ul>
<li>设置 Consumer 端参数：enable.auto.commit</li>
<li>设置 Consumer 端参数：auto.commit.interval.ms</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"localhost:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"auto.commit.interval.ms"</span><span class="token punctuation">,</span> <span class="token string">"2000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>
     consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"foo"</span><span class="token punctuation">,</span> <span class="token string">"bar"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span>
             <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>





<h5 id="手动提交位移"><a href="#手动提交位移" class="headerlink" title="手动提交位移"></a>手动提交位移</h5><ul>
<li>设置 Consumer 端参数：enable.auto.commit</li>
<li>然后我们就需要手动提交位移了，手动提交位移，Kafka提供了两种方式：同步提交方式和异步提交方式</li>
</ul>
<h6 id="同步提交方式"><a href="#同步提交方式" class="headerlink" title="同步提交方式"></a>同步提交方式</h6><ul>
<li>KafkaConsumer#commitSync()</li>
<li>提交失败了，会自动重试，再次提交，所以会影响消费性能</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">process</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 处理消息</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">CommitFailedException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token function">handle</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 处理提交失败异常</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h6 id="异步提交方式"><a href="#异步提交方式" class="headerlink" title="异步提交方式"></a>异步提交方式</h6><ul>
<li>KafkaConsumer#commitAsync()</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">process</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 处理消息</span>
    consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token punctuation">(</span>offsets<span class="token punctuation">,</span> exception<span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span>
            <span class="token function">handle</span><span class="token punctuation">(</span>exception<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h6 id="同步提交方式-异步提交方式"><a href="#同步提交方式-异步提交方式" class="headerlink" title="同步提交方式+异步提交方式"></a>同步提交方式+异步提交方式</h6><ul>
<li>同步会出现的问题：是阻塞的，会降低 Consumer 的 TPS ；好处是会自动重试，提交不成功的话，不会拉取新的消息；</li>
<li>异步会出现的问题：提交异常的话，不会重试；会导致消息重复消费</li>
<li>怎么办呢？结合两者，先使用异步提交一次，如果失败了，finally里使用同步方式</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
        <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">process</span><span class="token punctuation">(</span>records<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 处理消息</span>
        <span class="token function">commitAysnc</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 使用异步提交规避阻塞</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span> <span class="token keyword">catch</span><span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token function">handle</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 处理异常</span>
<span class="token punctuation">&#125;</span> <span class="token keyword">finally</span> <span class="token punctuation">&#123;</span>
    <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
        consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 最后一次提交使用同步阻塞式提交</span>
    <span class="token punctuation">&#125;</span> <span class="token keyword">finally</span> <span class="token punctuation">&#123;</span>
        consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h5 id="公司内部使用"><a href="#公司内部使用" class="headerlink" title="公司内部使用"></a>公司内部使用</h5><p>在公司内部默认是使用：手动提交位移</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>optionalConfig<span class="token punctuation">.</span><span class="token function">isTransactional</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span> <span class="token keyword">else</span> <span class="token punctuation">&#123;</span>
    properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>



<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ConsumeOptionalConfig</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//....</span>
    <span class="token keyword">private</span> <span class="token keyword">boolean</span> transactional <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
    <span class="token comment">//....</span>
<span class="token punctuation">&#125;</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>既然公司内部使用的手动提交，那么在哪里提交的位移呢？</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">commitInit</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token comment">//公司是为：每一个Consumer开了一个线程，后台手动提交位移</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>commitOffsetThread <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">TransactionalConsumer<span class="token punctuation">.</span>CommitOffsetThread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">this</span><span class="token punctuation">.</span>commitOffsetThread<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span>

<span class="token comment">//这是线程真正提交位移的方式，提交到 ZK 的</span>
<span class="token keyword">long</span> nextOffset <span class="token operator">=</span> currentOffset <span class="token operator">+</span> <span class="token number">1L</span><span class="token punctuation">;</span>
<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token class-name">ZookeeperConsumerConnector</span><span class="token punctuation">)</span><span class="token class-name">TransactionalConsumer</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span>connector<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">commitOffsetToZooKeeper</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">TopicAndPartition</span><span class="token punctuation">(</span><span class="token class-name">TransactionalConsumer</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span>topic<span class="token punctuation">,</span> partition<span class="token punctuation">)</span><span class="token punctuation">,</span> nextOffset<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">this</span><span class="token punctuation">.</span>logger<span class="token punctuation">.</span><span class="token function">info</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"commit offset: topic:%s, partition:%d, nextOffset: %s"</span><span class="token punctuation">,</span> <span class="token class-name">TransactionalConsumer</span><span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">.</span>topic<span class="token punctuation">,</span> partition<span class="token punctuation">,</span> nextOffset<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h5 id="Offset提交导致的问题"><a href="#Offset提交导致的问题" class="headerlink" title="Offset提交导致的问题"></a>Offset提交导致的问题</h5><p>上面说了 Offset 的提交，有两种方式：自动提交和手动提交，手动提交又分为：同步提交和异步提交</p>
<p>那么它们会导致什么问题呢？会不会导致消息的丢失消费和消息的重复消费？</p>
<p><strong>自动提交</strong></p>
<ul>
<li>自动提交会导致消息的丢失</li>
<li>自动提交会导致消息的重复消费</li>
</ul>
<p>为什么会导致丢失？是因为消息消费的流程是：Concumer 先 Pull 一部分消息到内存中，然后开始消费，但是需要提交给 Broker 的 Offset 是Pull下来的最大的Offset，由于提交 Offset 是自动的，有可能 Pull 下来的消息还没有消费完，Offset 已经提交了；然后如果从内存中消费出现了问题，那么会导致内存中剩余没消费就永远不会在消费了。</p>
<p>为什么会导致重复？是因为自动提交，默认周期是5秒，如果在第3秒的时候，Broker发生了 Rebalance，那么 Offset 就提交不上去，当 Rebalance 完成之后，这部分数据，还会被在消费一次。</p>
<p><strong>手动提交</strong></p>
<ul>
<li>手动提交方式，可以解决消息的重复消费和丢失问题，因为我消费一个，提交一次Offset</li>
<li>同步提交方式，会影响消费端的性能</li>
<li>异步提交方式，解决了性能问题，但是消费成功之后，位移提交失败，不会自动重试提交，如果我们在 callback 中手动重试，又有可能导致提交上去的是一个老的 Offset</li>
<li>异步+同步方式：每次提交Offset都是异步的，然后在 finally 中同步提交一次，可以完美避免以上问题</li>
</ul>
<p>怎么避免的呢？消费者 poll 方法内部有维护一个不可见的指针，commitAysnc 方法异步提交不管是否成功，poll 仍然能根据自己维护的指针位移消费数据，最后在finally内用同步方法， 同步最新的 Offset。 这样提交上去的就不是老的 Offset</p>
<p>如果你选择的是自动提交位移，那么就可能存在一个问题：只要 Consumer 一直启动着，它就会无限期地向位移主题写入消息。导致磁盘爆满；因为自动提交位移是后台定时提交的（auto.commit.interval.ms默认是5s）；</p>
<p>那么满了怎么办？满了就删除，怎么删除呢？</p>
<h4 id="位移主题中的过期数据（过期位移）"><a href="#位移主题中的过期数据（过期位移）" class="headerlink" title="位移主题中的过期数据（过期位移）"></a>位移主题中的过期数据（过期位移）</h4><p>我们知道所有的位移数据都是保存在 位移主题 中的，如果不删除的话，位移主题就会无限的膨胀</p>
<p>为了避免该主题无限期膨胀。Kafka 会定期的清理位移主题中的数据。</p>
<p><strong>那么什么样的数据被称为过期数据呢？</strong></p>
<p>我们知道位移主题中存了三类消息，这里以 位移消息 为例；</p>
<p>位移消息的消息格式是Map格式，key是 groupid+topic+partition ；value是位移数据</p>
<p>举个例子说：</p>
<p>一个消费者组（假设groupid为：consumer_group_1），这个消费者组消费一个 Topic（假设消费：topic_a）；然后这个 Topic 有3个 Partition；</p>
<p>生产者 源源不断的向 Topic 中写数据，消费者组不停地消费数据，消费一个数据，就向 位移主题 中发一个位移消息；</p>
<p>那么这里的位移消息可能就是下面这样的：</p>
<p>consumer_group_1+topic_a+partition_1  ：  2345</p>
<p>consumer_group_1+topic_a+partition_1  ：  2346</p>
<p>consumer_group_1+topic_a+partition_1  ：  2347</p>
<p>。。。。。</p>
<p>最终，我们就会发现，同一个key就会存在很多数据，而且只有最后一条数据，才是有效的。那么之前的数据，都<strong>被称为过期数据</strong>；</p>
<p>再次之外，还有一种情况：</p>
<p>在 Broker 端有一个参数：<code>offsets.retention.minutes</code>,这个参数表明了 offset 的保留时间，什么意思呢？</p>
<p>就是说：我们提交到 位移主题 中的消息，并不会永远的保存，在超过了这个配置时间后，Kafka后台有一个线程，就会把这个Offset删掉</p>
<p>这个值一般是 7 天。</p>
<p>也就是说：如果你的消费者7天都没有上线了，或者7天都没有提交 offset 了，Kafka就会把这个消费者组的 位移数据 判定为过期数据。并删除</p>
<h4 id="位移主题中的过期数据（过期位移）清理"><a href="#位移主题中的过期数据（过期位移）清理" class="headerlink" title="位移主题中的过期数据（过期位移）清理"></a>位移主题中的过期数据（过期位移）清理</h4><p>在上面我们知道了 位移主题 中的过期数据有两类：</p>
<ul>
<li>一类是：同一个<code>key</code>的过期数据</li>
<li>一类是：超过了<code>offsets.retention.minutes</code>的过期数据</li>
</ul>
<p><strong>第一类过期数据，Kafka是怎么清理的呢？</strong></p>
<p>答案就是 Compaction。</p>
<p>国内很多文献都将其翻译成压缩，我个人是有一点保留意见的。</p>
<p>在英语中，压缩的专有术语是 Compression，它的原理和 Compaction 很不相同，我更倾向于翻译成压实，或干脆采用 JVM 垃圾回收中的术语：整理。</p>
<p>它的原理很简单：就是将：同一个 &lt;Group ID，主题名，分区号&gt; 的 Offset 进行压实整理，只保留最新的</p>
<img src="kafka从入门到入土.assets/image-20220828155424662.png" alt="image-20220828155424662" style="zoom: 50%;" />

<p>图中位移为 0、2 和 3 的消息的 Key 都是 K1。Compact 之后，分区只需要保存位移为 3 的消息，因为它是最新发送的。</p>
<p>Kafka 提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可压缩数据。这个后台线程叫 Log Cleaner。</p>
<p><strong>第二类过期数据，Kafka是怎么清理的呢？</strong></p>
<p>上面说到，Kafka有一个后台线程：Log Cleaner。</p>
<p>这个线程除了会清理第一类过期数据之外，还会清理第二类过期数据。</p>
<p>很多实际生产环境中都出现过位移主题无限膨胀占用过多磁盘空间的问题，如果你的环境中也有这个问题，我建议你去检查一下 Log Cleaner 线程的状态，通常都是这个线程挂掉了导致的。</p>
<p>Kafka 定期自动删除过期位移的条件就是，组要处于 Empty 状态（消费者组的状态机）。因此，如果你的消费者组停掉了很长时间（超过 7 天），那么 Kafka 很可能就把该组的位移数据删除了</p>
<h4 id="位移提交失败怎么办"><a href="#位移提交失败怎么办" class="headerlink" title="位移提交失败怎么办"></a>位移提交失败怎么办</h4><p>一般的失败，API会自动重试；</p>
<p>但是有一个异常叫做 CommitFailedException，这个异常抛出，说明位移的提交出现了大问题，需要人工介入了</p>
<p>那么这个异常是啥意思呢？什么时候会产生呢？产生了之后要怎么处理呢？</p>
<p><strong>什么是 CommitFailedException</strong></p>
<blockquote>
<p>Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. </p>
<p>This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. </p>
<p>You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.</p>
</blockquote>
<p>翻译过来就是：</p>
<blockquote>
<p>本次提交位移失败了，原因是消费者组已经开启了 Rebalance 过程，并且将要提交位移的分区分配给了另一个消费者实例。</p>
<p>出现这个情况的原因是：你的消费者实例连续两次调用 poll 方法的时间间隔超过了期望的 max.poll.interval.ms 参数值。这通常表明，你的消费者实例花费了太长的时间进行消息处理，耽误了调用 poll 方法。</p>
<p>你可以通过：增加期望的时间间隔 max.poll.interval.ms 参数值 或者 减少 poll 方法一次性返回的消息数量，即减少 max.poll.records 参数值。</p>
</blockquote>
<p><strong>那么什么时候会抛出这个异常呢？</strong></p>
<p>从源代码方面来说，CommitFailedException 异常通常发生在手动提交位移时，即用户显式调用 KafkaConsumer.commitSync() 方法时。</p>
<p>从使用场景来说，有两种典型的场景可能遭遇该异常。</p>
<p>场景一</p>
<ul>
<li><p>当消息处理的总时间超过预设的 max.poll.interval.ms 参数值时，Kafka Consumer 端会抛出 CommitFailedException 异常。</p>
</li>
<li><p>模拟异常产生：</p>
</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">…
<span class="token class-name">Properties</span> props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
…
props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"max.poll.interval.ms"</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"test-topic"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> 
    consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 使用Thread.sleep模拟真实的消息处理逻辑</span>
    <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">6000L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>场景二</p>
<ul>
<li>消费者组 Consumer Group  和 独立消费者 Standalone Consumer 拥有了相同的 group.id，当独立消费者程序手动提交位移时，Kafka 就会立即抛出 CommitFailedException 异常，因为 Kafka 无法识别这个具有相同 group.id 的消费者实例，于是就向它返回一个错误，表明它不是消费者组内合法的成员。</li>
<li>这种情况一般出现在很多部门消费同一个 Kafka 集群导致的，各个部门的消费者命名重复了，导致相同的 group.id</li>
</ul>
<p><strong>当前当异常出现了，我们应该怎么办呢？</strong></p>
<p>怎么解决问题，要先知道问题是怎么出现的。</p>
<p>比如在 场景一 中，我们知道产生问题的原因是：两次 poll() 方法调用的间隔超过了 max.poll.interval.ms</p>
<p>那么就简单了，针对 场景一 ，我们可以：</p>
<ul>
<li><strong>调大 max.poll.interval.ms 这个间隔时间</strong>，默认时间是 5分钟</li>
<li><strong>减少每次 poll() 拉取的消息数量</strong>：我们知道一次 poll() 方法，默认拉 500 条，因为拉取的太多了，消费的慢，所以导致两次 poll() 时间间隔太长</li>
<li>接第二条，‘消费的慢’，那我们就提到消息速率，<strong>优化代码，减少每条消息的处理时间</strong>，提高TPS</li>
<li>除了优化代码，提交消费速度，还可以<strong>使用多线程，提高消费速度</strong>，但是要注意多线程下的位移提交问题</li>
</ul>
<p>针对场景二呢，上面四个办法就不能用了，不过一般大公司下，消费者都是需要申请的，如果重复了，一般是申请不了的。</p>
<h2 id="多线程消费"><a href="#多线程消费" class="headerlink" title="多线程消费"></a>多线程消费</h2><h3 id="Kafka-Java-Consumer-的单线程设计"><a href="#Kafka-Java-Consumer-的单线程设计" class="headerlink" title="Kafka Java Consumer 的单线程设计"></a>Kafka Java Consumer 的单线程设计</h3><p>为什么 Kafka Java Consumer 要设计成单线程，看一下发展历史就明白了了</p>
<p>在目前的 KafkaConsumer 的API出现之前，有一个 Scala 版本的 Consumer 的API，这组 Scale 的API 被称为老版本 Consumer</p>
<p>在老版本 Consumer 中，Consumer 的设计是多线程的架构：</p>
<ul>
<li>每个 Consumer 实例在内部为所有订阅的 Topic 分区，创建对应的消息获取线程（就是一个分区一个线程），称为 Fetcher 线程</li>
<li>老版本的 Consumer 同时也是阻塞的，Consumer 实例启动后，内部会创建阻塞式的消息获取迭代器</li>
</ul>
<p>那么为什么后来变成单线程的了呢？</p>
<ul>
<li>主要是因为老版本的 Consumer 是阻塞的</li>
<li>而在大部分业务场景下，比如对数据的过滤，连接，分组，就不能是阻塞式的。</li>
<li>所以在新版的 Consumer 下，Kafka 设计了 单线程+轮训 的机制</li>
</ul>
<p>采用单线程还有另外一个考虑</p>
<ul>
<li>就是单线程可以简化 Consumer 的设计，在任何编程语言中，单线程都比多线程更方便维护</li>
</ul>
<p>不过，虽然 Consumer 的设计是单线程的，但是并不意味着我们就不能多线程了。</p>
<p>虽然 KafkaConsumer 的类的设计是单线程的，而且<strong>不是线程安全</strong>的。但是只是说明 拉取消息 的逻辑是单线程的</p>
<p>但是消息拉取之后，怎么处理消息，完全是由开发者决定的，此时可以<strong>手动开发多线程</strong>进行消费</p>
<h3 id="多线程方案"><a href="#多线程方案" class="headerlink" title="多线程方案"></a>多线程方案</h3><p>总体来说有两种方案。</p>
<h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a><strong>方案一</strong></h4><p>消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程。</p>
<p>简单地说：一个线程负责一个分区</p>
<img src="kafka从入门到入土.assets/image-20230214112054515.png" alt="image-20230214112054515" style="zoom: 33%;" />

<h4 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a><strong>方案二</strong></h4><p>消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑</p>
<p>简单的说：一个或多个线程负责拉取消息，多个线程负责处理消息</p>
<img src="kafka从入门到入土.assets/image-20230214112223276.png" alt="image-20230214112223276" style="zoom:33%;" />



<h4 id="方案对比"><a href="#方案对比" class="headerlink" title="方案对比"></a><strong>方案对比</strong></h4><table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>方案一</td>
<td>方便实现</td>
<td>占用更多的系统资源</td>
</tr>
<tr>
<td>方案一</td>
<td>速度快，没有线程间的交互开销</td>
<td>线程数受限于 Topic 的分区数（最多一个分区一个线程），扩展性差</td>
</tr>
<tr>
<td>方案一</td>
<td>易于维护分区间的消息顺序</td>
<td>线程自己拉取消息，自己处理消息，可能导致超时，引发Rebalance</td>
</tr>
<tr>
<td>方案二</td>
<td>可独立扩展获取消息线程数和处理消息线程数</td>
<td>实现难度高</td>
</tr>
<tr>
<td>方案二</td>
<td>伸缩性好</td>
<td>难以维护分区内的消息消费顺序</td>
</tr>
<tr>
<td>方案二</td>
<td></td>
<td>处理链路长，不利于 Offset 的提交管理</td>
</tr>
</tbody></table>
<h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a><strong>代码实现</strong></h4><p>方案一</p>
<ul>
<li>这段代码创建了一个 Runnable 类，表示执行消费获取和消费处理的逻辑。每个 KafkaConsumerRunner 类都会创建一个专属的 KafkaConsumer 实例。在实际应用中，你可以创建多个 KafkaConsumerRunner 实例，并依次执行启动它们，以实现方案 1 的多线程架构。</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">KafkaConsumerRunner</span> <span class="token keyword">implements</span> <span class="token class-name">Runnable</span> <span class="token punctuation">&#123;</span>
     <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">AtomicBoolean</span> closed <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AtomicBoolean</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">KafkaConsumer</span> consumer<span class="token punctuation">;</span>


     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         <span class="token keyword">try</span> <span class="token punctuation">&#123;</span>
             consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token class-name">Arrays</span><span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
             <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>closed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
      <span class="token class-name">ConsumerRecords</span> records <span class="token operator">=</span> 
        consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofMillis</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                 <span class="token comment">//  执行消息处理逻辑</span>
             <span class="token punctuation">&#125;</span>
         <span class="token punctuation">&#125;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">WakeupException</span> e<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
             <span class="token comment">// Ignore exception if closing</span>
             <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>closed<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">throw</span> e<span class="token punctuation">;</span>
         <span class="token punctuation">&#125;</span> <span class="token keyword">finally</span> <span class="token punctuation">&#123;</span>
             consumer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token punctuation">&#125;</span>
     <span class="token punctuation">&#125;</span>


     <span class="token comment">// Shutdown hook which can be called from a separate thread</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">shutdown</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
         closed<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         consumer<span class="token punctuation">.</span><span class="token function">wakeup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<p>方案二</p>
<ul>
<li>这段代码最重要的地方是最后一行：当 Consumer 的 poll 方法返回消息后，由专门的线程池来负责处理具体的消息。调用 poll 方法的主线程不负责消息处理逻辑，这样就实现了方案 2 的多线程架构。</li>
</ul>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> consumer<span class="token punctuation">;</span>
<span class="token keyword">private</span> <span class="token class-name">ExecutorService</span> executors<span class="token punctuation">;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


<span class="token keyword">private</span> <span class="token keyword">int</span> workerNum <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">;</span>
executors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor</span><span class="token punctuation">(</span>
  workerNum<span class="token punctuation">,</span> workerNum<span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">,</span> <span class="token class-name">TimeUnit</span><span class="token punctuation">.</span><span class="token constant">MILLISECONDS</span><span class="token punctuation">,</span>
  <span class="token keyword">new</span> <span class="token class-name">ArrayBlockingQueue</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
  <span class="token keyword">new</span> <span class="token class-name">ThreadPoolExecutor<span class="token punctuation">.</span>CallerRunsPolicy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>  <span class="token punctuation">&#123;</span>
  <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> 
    consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">final</span> <span class="token class-name">ConsumerRecord</span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    executors<span class="token punctuation">.</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Worker</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="重平衡与协调者"><a href="#重平衡与协调者" class="headerlink" title="重平衡与协调者"></a>重平衡与协调者</h2><h3 id="什么是重平衡"><a href="#什么是重平衡" class="headerlink" title="什么是重平衡"></a>什么是重平衡</h3><p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p>
<p>比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance。</p>
<h3 id="什么时候会重平衡"><a href="#什么时候会重平衡" class="headerlink" title="什么时候会重平衡"></a>什么时候会重平衡</h3><ul>
<li>Consumer Group 内 Consumer实例 数量发生变化（新增或减少）；</li>
<li>Consumer Group 订阅的 Topic 数发生变化；</li>
<li>Consumer Group 订阅的 Topic 的 Partition 数量发生变化</li>
</ul>
<h3 id="重平衡策略"><a href="#重平衡策略" class="headerlink" title="重平衡策略"></a>重平衡策略</h3><ul>
<li>举例：比如组内有2个消费者，这个组消费 TopicA 和 TopicB ,其中 Consumer-1 消费 TopicA，Consumer-2 消费 TopicB，当该 Consumer Group 新订阅一个 TopicC 的时候，会不会 Consumer-1 消费到 TopicB，Consumer-2 消费到 TopicA</li>
</ul>
<p>Kafka 有三种策略保证重平衡后的公平</p>
<p><strong>Rnage 分配策略</strong></p>
<p>Range分配策略是面向每个 Topic 的，首先会对同一个 Topic 里面的 Partition 按照序号进行排序，并把消费者线程按照字母顺序进行排序。然后用分区数除以消费者线程数量来判断每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。 </p>
<p><strong>RoundRobin策略</strong></p>
<p>RoundRobin策略的原理是将 Consumer Group 内所有 Consumer 以及订阅的所有 Topic 的 Partition 按照字典序排序，然后通过轮询算法逐个将分区以此分配给每个消费者。 使用RoundRobin分配策略时会出现两种情况： </p>
<ul>
<li><p>如果同一消费组内，所有的消费者订阅的消息都是相同的，那么 RoundRobin 策略的分区分配会是均匀的。</p>
</li>
<li><p>如果同一消费者组内，所订阅的消息是不相同的，那么在执行分区分配的时候，就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个 topic，那么在分配分区的时候，此消费者将不会分配到这个 topic 的任何分区。</p>
</li>
</ul>
<p><strong>Sticky分配策略</strong></p>
<p>Sticky分配策略，这种分配策略是在 Kafka 的 0.11.X 版本才开始引入的，是目前最复杂也是最优秀的分配策略。 Sticky分配策略的原理比较复杂，它的设计主要实现了两个目的： </p>
<ul>
<li><p>分区的分配要尽可能的均匀；</p>
</li>
<li><p>分区的分配尽可能的与上次分配的保持相同。 如果这两个目的发生了冲突，优先实现第一个目的。</p>
</li>
</ul>
<h3 id="什么是协调者Coordinator"><a href="#什么是协调者Coordinator" class="headerlink" title="什么是协调者Coordinator"></a>什么是协调者Coordinator</h3><p>所谓协调者，在 Kafka 中对应的术语是 Coordinator，它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。</p>
<ul>
<li><p>协调者 coordinators 是协调管理 Consumer Group 的一个程序，运行在broker上的</p>
</li>
<li><p>每一个broker在启动时都会启动 coordinator 组件（coordinator程序），也就是说每个 Broker 都有具备称为 Coordinator 的能力</p>
</li>
</ul>
<p>具体来讲，Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。</p>
<p>同样地，当 Consumer 应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator 负责执行消费者组的注册、成员管理记录等元数据管理操作。</p>
<h3 id="消费者组是怎么找到自己的coordinator的"><a href="#消费者组是怎么找到自己的coordinator的" class="headerlink" title="消费者组是怎么找到自己的coordinator的"></a>消费者组是怎么找到自己的coordinator的</h3><p>既然 Coordinator 是运行在 Broker上 的一个程序，那么一个消费者组，是怎么找到自己的 Coordinator 的呢？</p>
<p>在<a href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8ETCP%E8%BF%9E%E6%8E%A5">消费者与TCP连接</a>这一节中，我们知道消费者在启动的时候，会创建三类 TCP 连接</p>
<ul>
<li>第一类：与负载最小的 Broker 创建连接，发送 FIndCoordinator 请求，希望该 Broker 告诉自己谁是我的协调者；</li>
<li>第二类：与 Coordinator 创建TCP连接，加入组，分配方案，位移获取和提交等</li>
<li>第三类：与 要消费的分区的副本所在 Broker 创建 TCP 连接，真正开始消费数据</li>
</ul>
<p>所以，消费者组找到自己的 Coordinator 是在第一类 TCP 请求中找到的</p>
<p>那么 具体是怎么找到的呢？是通过之前说过的 __consumer_offset 这个主题来找的</p>
<p>分为两步</p>
<ul>
<li>获取当前 Consumer Group 的 groupid，然后hash得到hash值；</li>
<li>获取__consumer_offset 的分区数，默认是50</li>
<li>计算 ：abs ( hash % 50 ) &#x3D; 分区号</li>
<li>然后，找到这个分区号的 leader 副本所在的 broker ；这个broker就是这个消费者的coordinator</li>
</ul>
<h3 id="重平衡的缺点"><a href="#重平衡的缺点" class="headerlink" title="重平衡的缺点"></a>重平衡的缺点</h3><ul>
<li>会STW（stop the world）：消费者会全部停止消费</li>
<li>时间太慢了，几百个消费者重平衡一次，要几个小时</li>
<li>Rebalance 的设计是要求所有 Consumer 实例共同参与，全部重新分配所有分区</li>
<li>在 Rebalance 过程中，所有 Consumer 实例都要参与，所以在整个过程中都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大</li>
</ul>
<h3 id="避免消费者组重平衡"><a href="#避免消费者组重平衡" class="headerlink" title="避免消费者组重平衡"></a>避免消费者组重平衡</h3><p>首先，明确一个概念，目前Rebalance的弊端（慢，STW）这2个弊端，社区是没有办法解决的；</p>
<p>针对Rebalance的效率低的情况，社区采用了StickyAssignor策略来提升性能；</p>
<p>既然无法解决，那我们只能尽量避免，怎么避免呢？就要从导致Rebalance发生的三种情况来看</p>
<ul>
<li>组成员数量发生变化（99%的Rebalance都是这个原因）</li>
<li>订阅主题数量发生变化（一般是程序开发者主动操作，无法避免）</li>
<li>订阅主题的分区数发生变化（一般是程序开发者主动操作，无法避免）</li>
</ul>
<p>组成员数量发生变化，变化分为两种，一种是增加，一种是减少</p>
<ul>
<li>增加：一般都是程序开发者主动操作，比如为了提升topic的消费速率，无法避免</li>
<li>减少：如果是主动停掉的，那自不必说，无法避免；</li>
<li>减少：不是主动停掉的，是被 Coordinator 错误地认为“已停止”从而被“踢出”Group。如果是这个原因导致的 Rebalance，我们就不能不管了。</li>
</ul>
<p><strong>什么时候coordinator会认为consumer实例已停止</strong></p>
<ul>
<li>Coordinator 没有收到 Consumer 的心跳，就会让 Consumer 离组，重新 Rebalance<ul>
<li>Consumer 端有个参数，叫 session.timeout.ms，默认10秒；</li>
<li>Coordinator 在10s内没有收到 Consumer 的心跳，就Rebalance</li>
<li>心跳是consumer主动给coordinator的，那么多久一次呢？是由参数：heartbeat.interval.ms控制的；</li>
<li>推荐配置：session.timeout.ms&#x3D;6s，heartbeat.interval.ms&#x3D;2s：要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求</li>
</ul>
</li>
<li>Consumer 实例在一定时间内消费不完已经 pull() 下来的消息，就会主动离组，重新Rebalance<ul>
<li>Consumer 端有个参数，max.poll.interval.ms 参数，默认5分钟</li>
<li>一个consumer在5分钟内，没有消费完拉取的数据，就Rebalance</li>
</ul>
</li>
<li>consumer端的GC情况</li>
</ul>
<p>standalone consumer 就没有 rebalance 一说了。 它的特点主要是灵活。</p>
<p>虽然社区一直在改进rebalance的性能，但大数据量下consumer group机制依然有很多弊病（比如rebalance太慢等）</p>
<p>所以很多大数据框架(Spark &#x2F;Flink)的kafka connector并不使用group机制，而是使用standalone consumer</p>
<h3 id="怎么排查生产是否重平衡过多"><a href="#怎么排查生产是否重平衡过多" class="headerlink" title="怎么排查生产是否重平衡过多"></a>怎么排查生产是否重平衡过多</h3><p>主动去排查：去找Coordinator所在的broker日志，如果经常发生rebalance，会有类似于”(Re)join group” 之类的日志</p>
<p>被动排查：一般 Rebalance 过多，会降低消费者能力，间接的就会出现消息堵，可以配置相关告警</p>
<h3 id="重平衡核心全流程"><a href="#重平衡核心全流程" class="headerlink" title="重平衡核心全流程"></a>重平衡核心全流程</h3><p>重平衡是怎么做到的？</p>
<p>在 Kafka 中，每个 Consumer 都会通过<strong>心跳线程</strong>，定期的向 Coordinator 汇报自己的状态；</p>
<p>同时 Coordinator 也会通过<strong>心跳线程</strong>，告诉 Consumer ：我收到了你的汇报；</p>
<p>如果 Consumer 超时没有汇报；说明这个 Cnnsumer 有问题了，此时 Coordinator 就会开启重平衡</p>
<p>Coordinator 会通过<strong>心跳线程</strong>，向这个 Consumner 所在的 Group 下的所有 Consumer，发送消息：<strong>REBALANCE_IN_PROGRESS</strong></p>
<p>当 Consumer 收到这种消息之后，就知道要开启重平衡了</p>
<p>而 Coordinator 具体是怎么实现重平衡的呢？</p>
<p>其实是通过控制 Consumer Group 的状态来完成重平衡的。这是<strong>理解重平衡的基础</strong>。</p>
<p>下面我们就来看看 消费者组的状态机，这是<strong>理解重平衡的基础</strong>；</p>
<h4 id="消费者组的状态机"><a href="#消费者组的状态机" class="headerlink" title="消费者组的状态机"></a>消费者组的状态机</h4><p>消费者组的状态主要有以下 五个：</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Empty</td>
<td>组内没有任何成员，但消费者可能存在已经提交的数据，并且未过期：<a href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%B8%AD%E7%9A%84%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE%EF%BC%88%E8%BF%87%E6%9C%9F%E4%BD%8D%E7%A7%BB%EF%BC%89">位移主题中的过期数据（过期位移）</a></td>
</tr>
<tr>
<td>Dead</td>
<td>组内没有任何成员，Coordinator 已经把这个消费者组的元数据信息删除了</td>
</tr>
<tr>
<td>PreparingRebalance</td>
<td>消费者组准备开启重平衡，此时所有成员都要重新申请加入组</td>
</tr>
<tr>
<td>CompletingRebalance</td>
<td>消费者组下的所有成员都已经加入，等待Leader分配方案，老版本中这个状态叫：AwatingSync</td>
</tr>
<tr>
<td>Stable</td>
<td>消费者组的稳定状态，表示重平衡已经完成，可以正常开启消费了</td>
</tr>
</tbody></table>
<pre class="mermaid">stateDiagram
    direction LR
    Empty-->Dead: 组信息过期被删除
    Empty-->PreparingRebalance:准备开启rebalance
    PreparingRebalance-->Dead:位移主题分区Leader发生变化
    PreparingRebalance-->Empty:组内所有成员离组
    PreparingRebalance-->CompletingRebalance:有成员入组
    CompletingRebalance-->Dead:位移主题分区Leader发生变化
    CompletingRebalance-->PreparingRebalance:成员加入或离开
    CompletingRebalance-->Stable:Leader完成分配
    Stable-->Dead:位移主题分区Leader发生变化
    Stable-->PreparingRebalance:心跳过期/成员离组/新成员加入
    
    %% 给状态添加样式
    classDef badBadEvent fill:green,color:white,font-weight:bold,stroke-width:2px,stroke:yellow
    class Empty badBadEvent
    class PreparingRebalance badBadEvent
    class CompletingRebalance badBadEvent
    class Stable badBadEvent
    class Dead badBadEvent</pre>



<p>一个消费者组最开始是 Empty 状态</p>
<p>当重平衡过程开启后，它会被置于 PreparingRebalance 状态等待成员加入</p>
<p>之后变更到 CompletingRebalance 状态等待分配方案</p>
<p>最后流转到 Stable 状态完成重平衡</p>
<p>当有新成员加入或已有成员退出时，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态，此时，所有现存成员就必须重新申请加入组。</p>
<p>当所有成员都退出组后，消费者组状态变更为 Empty</p>
<h4 id="重平衡流程"><a href="#重平衡流程" class="headerlink" title="重平衡流程"></a>重平衡流程</h4><h5 id="场景一：新成员入组"><a href="#场景一：新成员入组" class="headerlink" title="场景一：新成员入组"></a>场景一：新成员入组</h5><pre class="mermaid">sequenceDiagram
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，已收到
    成员2->>协调者: joinGroup请求：你好协调者，我请求加入组，我要消费的是主题是 B
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，REBALANCE_IN_PROGRESS,重平衡，你需要重新入组
    成员1->>协调者: joinGroup请求：你好协调者，我请求加入组，我要消费的是主题是 A
    协调者-->>成员2: joinGroup响应：你好成员2，你已成功入组，你是这组的Leader<br/>这组的订阅信息有：{成员1->主题A，成员2->主题B}
    协调者-->>成员1: joinGroup响应：你好成员1，你已成功入组，当前组的Leader是成员2，请等待分配方案
    成员1->>协调者: syncGroup请求：你好协调者，我是成员1，等待分配方案
    成员2->>协调者: syncGroup请求：你好协调者，我是成员2，也是这个组的Leader<br/>以下是我的分配方案：{成员1->主题A分区0，成员2->主题B分区0}
    协调者-->>成员1: syncGroup响应：你好成员1，你负责消费主题A的0分区
    协调者-->>成员2: syncGroup响应：你好成员2，你负责消费主题B的0分区
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，已收到
    成员2->>协调者: 心跳请求：你好协调者，我是组内的成员2，我还活着
    协调者-->>成员2: 心跳响应：你好成员2，已收到</pre>



<h5 id="场景二：组成员主动离组"><a href="#场景二：组成员主动离组" class="headerlink" title="场景二：组成员主动离组"></a>场景二：组成员主动离组</h5><pre class="mermaid">sequenceDiagram
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，已收到
    成员2->>协调者: 心跳请求：你好协调者，我是组内的成员2，我还活着
    协调者-->>成员2: 心跳响应：你好成员2，已收到
    成员1->>协调者: leaveGroup请求：你好协调者，我是组内的成员1，申请主动离组
    协调者-->>成员1: leaveGroup响应：你好成员1，已收到
    成员2->>协调者: 心跳请求：你好协调者，我是组内的成员2，我还活着
    协调者-->>成员2: 心跳响应：你好成员2，REBALANCE_IN_PROGRESS,重平衡，你需要重新入组
    成员2->>协调者: joinGroup请求：你好协调者，我请求加入组，我要消费的是主题是 B
    协调者-->>成员2: joinGroup响应：你好成员2，你已成功入组，你是这组的Leader<br/>这组的订阅信息有：{成员2->主题B}
    成员2->>协调者: syncGroup请求：你好协调者，我是成员2，也是这个组的Leader<br/>以下是我的分配方案：{成员2->主题B分区0}
    协调者-->>成员2: syncGroup响应：你好成员2，你负责消费主题B的0分区
    成员2->>协调者: 心跳请求：你好协调者，我是组内的成员2，我还活着
    协调者-->>成员2: 心跳响应：你好成员2，已收到</pre>



<h5 id="场景三：组成员崩溃离组"><a href="#场景三：组成员崩溃离组" class="headerlink" title="场景三：组成员崩溃离组"></a>场景三：组成员崩溃离组</h5><pre class="mermaid">sequenceDiagram
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，已收到
    成员2->>协调者: 心跳请求：你好协调者，我是组内的成员2，我还活着
    协调者-->>成员2: 心跳响应：你好成员2，已收到
    note left of 成员2: 成员2此时已离线
    协调者->>协调者: 发现成员2已经很长时间没有汇报了
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，REBALANCE_IN_PROGRESS,重平衡，你需要重新入组
    成员1->>协调者: joinGroup请求：你好协调者，我请求加入组，我要消费的是主题是 A
    协调者-->>成员1: joinGroup响应：你好成员1，你已成功入组，你是这组的Leader<br/>这组的订阅信息有：{成员1->主题A}
    成员1->>协调者: syncGroup请求：你好协调者，我是成员1，也是这个组的Leader<br/>以下是我的分配方案：{成员1->主题A分区0}
    协调者-->>成员1: syncGroup响应：你好成员1，你负责消费主题A的0分区
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者-->>成员1: 心跳响应：你好成员1，已收到</pre>



<h5 id="场景四：重平衡时协调者对组内成员提交位移的处理"><a href="#场景四：重平衡时协调者对组内成员提交位移的处理" class="headerlink" title="场景四：重平衡时协调者对组内成员提交位移的处理"></a>场景四：重平衡时协调者对组内成员提交位移的处理</h5><pre class="mermaid">sequenceDiagram
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
      协调者-->>成员1: 心跳响应：你好成员1，已收到
      协调者->>协调者: 此时发现需要重平衡
    成员1->>协调者: 心跳请求：你好协调者，我是组内的成员1，我还活着
    协调者->>成员1: 心跳响应：你好成员1，REBALANCE_IN_PROGRESS,重平衡，你需要重新入组
    成员1->>成员1: 必须赶在超时时间内提交位移
    note right of 成员1 : 赶在超时时间内提交位移
    成员1->>协调者: 提交位移请求：你好协调者，我要提交的位移是：{....}
    协调者->>成员1: 提交位移响应：你好成员1，位移数据已收到
    note right of 成员1 : 如果提交失败了，这部分数据在重平衡之后就会被重新消费</pre>





<h4 id="重平衡的一些问题"><a href="#重平衡的一些问题" class="headerlink" title="重平衡的一些问题"></a>重平衡的一些问题</h4><p>joingroup时等待所有消费者上报订阅信息，协调者通过什么判断所有消费者都已经上报了？</p>
<ul>
<li>join group时也是有一个总的超时时间的（取所有member最大的rebalance超时时间），靠这个作为判断是否进入到下一阶段的阈值。</li>
<li>如果在这次 Rebalance 期间，有 消费者 超时没有上报信息，那么这个消费者会被排除在这轮 Rebalance 之外</li>
</ul>
<p>如果在超时时间之后，排除在外的 消费者 此时上报了信息，怎么办？</p>
<ul>
<li>相当于 新成员入组，重新 Rebalance</li>
</ul>
<h2 id="副本机制"><a href="#副本机制" class="headerlink" title="副本机制"></a>副本机制</h2><p>我们之前谈到过，Kafka 是有 Topic 概念的，而每个 Topic 又进一步划分成若干个 Partition。</p>
<p>每个 Partition 配置有若干个 Replica，Replica 的概念实际上是在 Partition 层级下定义的</p>
<h3 id="什么是副本"><a href="#什么是副本" class="headerlink" title="什么是副本"></a>什么是副本</h3><p>所谓副本（Replica），本质就是一个只能追加写消息的提交日志。</p>
<p>同一个 Partition 下的所有 Replica 保存有相同的消息序列，这些 Replica 分散保存在不同的 Broker 上，从而能够对抗部分 Broker 宕机带来的数据不可用。</p>
<p>在实际生产环境中，每台 Broker 都可能保存有各个 Topic 下不同 Partition 的不同 Replica，因此，单个 Broker 上存有成百上千个 Replica 的现象是非常正常的。</p>
<p>下图展示的是一个有 3 台 Broker 的 Kafka 集群上的副本分布情况。</p>
<p>从这张图中，我们可以看到，主题 1 分区 0 的 3 个副本分散在 3 台 Broker 上，其他主题分区的副本也都散落在不同的 Broker 上，从而实现数据冗余。</p>
<img src="kafka从入门到入土.assets/image-20230214160607518.png" alt="image-20230214160607518" style="zoom:33%;" />



<h3 id="副本之间数据是怎么同步的"><a href="#副本之间数据是怎么同步的" class="headerlink" title="副本之间数据是怎么同步的"></a>副本之间数据是怎么同步的</h3><p>我们知道 Replica 是用来冗余数据的，同一个 Partiton 下的所有 Replica 的数据都应该是一模一样的，顺序都是一样的</p>
<p>那么这么多的 Replica，是怎么进行 Replica 之间的数据同步的呢？</p>
<p>Kafka使用的解决方案：就是采用<strong>基于领导者（Leader-based）的副本机制</strong></p>
<img src="kafka从入门到入土.assets/image-20230214161048286.png" alt="image-20230214161048286" style="zoom:33%;" />

<ul>
<li>在 Kafka 中，副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个 Leader Replica，剩余的是 Follower Replica</li>
<li>Kafka 的副本机制比其他分布式系统要更严格一些。在 Kafka 中，Follower Replica 是不对外提供服务的。所有的读写请求都必须由 Leader Replica所在的 Broker负责处理。而 Follower 的任务只有一个：就是从 Leader 异步拉取消息，并写入到自己的提交日志中，从而实现与 Leader 的同步。</li>
<li>当 Leader Replica 挂掉了，或者说 Leader Replica 所在的 Broker 宕机时，Kafka 依托于 ZK 进行新的 Leader Replica 的选举</li>
</ul>
<p>你一定要特别注意上面的第二点，即追随者副本是不对外提供服务的。</p>
<p>原因归咎于两点：方便 Read-your-writes ，同时方便实现单调读（Monotonic Reads）</p>
<h3 id="Follower不提供服务的优点"><a href="#Follower不提供服务的优点" class="headerlink" title="Follower不提供服务的优点"></a>Follower不提供服务的优点</h3><p>有两个好处</p>
<h4 id="方便实现“Read-your-writes”"><a href="#方便实现“Read-your-writes”" class="headerlink" title="方便实现“Read-your-writes”"></a>方便实现“Read-your-writes”</h4><p>所谓 Read-your-writes，顾名思义就是，当你使用生产者 API 向 Kafka 成功写入消息后，马上使用消费者 API 去读取刚才生产的消息。</p>
<p>举个例子，比如你平时发微博时，你发完一条微博，肯定是希望能立即看到的，这就是典型的 Read-your-writes 场景。如果允许追随者副本对外提供服务，由于副本同步是异步的，因此有可能出现追随者副本还没有从领导者副本那里拉取到最新的消息，从而使得客户端看不到最新写入的消息。</p>
<h4 id="方便实现单调读（Monotonic-Reads）"><a href="#方便实现单调读（Monotonic-Reads）" class="headerlink" title="方便实现单调读（Monotonic Reads）"></a>方便实现单调读（Monotonic Reads）</h4><p>什么是单调读呢？就是对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。</p>
<p>如果允许追随者副本提供读服务，那么假设当前有 2 个追随者副本 F1 和 F2，它们异步地拉取领导者副本数据。倘若 F1 拉取了 Leader 的最新消息而 F2 还未及时拉取，那么，此时如果有一个消费者先从 F1 读取消息之后又从 F2 拉取消息，它可能会看到这样的现象：第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性。但是，如果所有的读请求都是由 Leader 来处理，那么 Kafka 就很容易实现单调读一致性。</p>
<p>现在我们知道了 Replica 的同步机制，和 Follower Replica 不对外提供服务的原因，接下来还有两个问题，我们一一来看：</p>
<p>Kafka 是怎么保证 Replica 的数据一致性的</p>
<p>当 Leader Replica 挂掉之后，Kafka 是怎么进行选举新的 Leader Replica 的</p>
<h3 id="怎么保证-副本数据一致性"><a href="#怎么保证-副本数据一致性" class="headerlink" title="怎么保证 副本数据一致性"></a>怎么保证 副本数据一致性</h3><p>我们知道 Kafka 的 Partition 有很多个 Replica</p>
<p>Replica 分为 Leader Replica 和 Follower Replica</p>
<p>Leader Replica 对外提供读写服务，Follower Replica 只是从 Leader Replica 异步同步数据，不对外提供任何服务；</p>
<p>那么，Kakfa是怎么保证这些 Replica 内的数据是一致的呢？</p>
<h4 id="In-Sync-Replicas（ISR）"><a href="#In-Sync-Replicas（ISR）" class="headerlink" title="In-Sync Replicas（ISR）"></a><strong>In-Sync Replicas（ISR）</strong></h4><p>既然 Follower Replica 是异步的方式，从Leader Replica 同步数据的，那么就一定会存在延迟；</p>
<p>就像 Mysql 的主从一样，主要涉及到数据同步，就一定会有延迟，无外乎：延迟的大小是多少。</p>
<p>Kafka 知道这个延迟是无法避免的，所以，Kafka 维护了一个集合，这个集合中保存的是：与Leader同步的Follower；</p>
<p>什么是与Leader同步的Follower？有同步的Follower，难道还有不同步的Follower？</p>
<ul>
<li>是的，有同步的，就有不同步的。</li>
<li>Kafka 有自己一套判定条件，只要 Follower Replica 满足了这个判定条件，Kafka 就认为这个 Follower 是同步的。就会放进 ISR 集合；</li>
<li>这个条件就是：replica.lag.time.max.ms，表示 Follower 副本能够落后 Leader 副本的最长时间间隔，默认是10S</li>
<li>也就是说：当 Follower 与 Leader 的同步时间差，在10秒内，Kafka就认为这个 Follower 是同步的。否则就是不同步的</li>
<li>ISR 集合有什么用的，主要是用来选举新的 Leader Replica 的，后面会说</li>
</ul>
<p>ISR 是一个动态调整的集合，当 Follower 落后于 Leader ，并且落后时间大于<code>replica.lag.time.max.ms</code>，Kafka 就会将这个 Follower 踢出 ISR；</p>
<p>同样的，当一个落后的 Follower 最终追上了 Leader ，Kafka 会将这个 Follower 在加入 ISR；</p>
<h4 id="ISR是怎么变化的"><a href="#ISR是怎么变化的" class="headerlink" title="ISR是怎么变化的"></a>ISR是怎么变化的</h4><p>Kafka 在启动的时候会开启两个任务</p>
<p>一个任务用来定期地检查是否需要调整 ISR 集合，这个周期是replica.lag.time.max.ms的一半，默认5秒；</p>
<p>当检测到 ISR 集合中有失效副本时，就会收缩 ISR 集合，当检查到有 Follower 的 HighWatermark （高水位）追赶上 Leader 时，就会扩充ISR。 </p>
<p>除此之外，当 ISR 集合发生变更的时候。还会将变更后的记录缓存到 isrChangeSet 中</p>
<p>另一个任务会周期性地检查 isrChangeSet，如果发现这个 isrChangeSet 有新的变更记录，那么它会在 ZK 中持久化一个节点。</p>
<p>然后因为 Controller（Kafka 控制器） 在这个 ZK 节点的路径上注册了一个Watcher，所以它就能够感知到ISR的变化，并向它所管理的broker发送更新元数据的请求。最后删除该ZK节点。 </p>
<p>Leader 副本天然就在 ISR 中</p>
<p>极端的情况：ISR 包含全部的 Replica，也有可能 ISR 中一个 Replica 都没有，如果一个都没有的话，说明 Leader 都挂了，此时就需要选举新的 Leader了。</p>
<h3 id="怎么进行选举新的-Leader-Replica"><a href="#怎么进行选举新的-Leader-Replica" class="headerlink" title="怎么进行选举新的 Leader Replica"></a>怎么进行选举新的 Leader Replica</h3><p>选举的时候，是通过 Controller（Kafka控制器）来处理的。 Coordinator（协调者）只是消费者组用来重平衡的；这两个不是一个概念；</p>
<p>当 ISR 不为空的时候，则选择其中一个作为新Leader，新的ISR则包含当前 ISR 中所有幸存的 Replica。</p>
<p>当 ISR 为空的时候，此时幸存的 Replica 都是非同步副本，也就是说：都是和 老的 Leader Replica 差距比较大的 Replica，如果此时从这些 非同步副本 中选举一个作为 Leader 的话，就会有消息丢失的风险；如果不选举，那就是 Kafka 服务不可用了。</p>
<p>当 ISR 为空的时候，如果进行选举，则这个选举叫做： Unclean 领导者选举，Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举</p>
<p>如果开启了  Unclean 领导者选举 ，相当于选择了可用性，牺牲了一致性；如果不选举，相当于选择了一致性，牺牲了可用性</p>
<p>建议不要开启，毕竟我们还可以通过其他的方式来提升高可用性。如果为了这点儿高可用性的改善，牺牲了数据一致性，那就非常不值当了。</p>
<h2 id="请求是怎么被处理的"><a href="#请求是怎么被处理的" class="headerlink" title="请求是怎么被处理的"></a>请求是怎么被处理的</h2><h3 id="kafka的请求分类"><a href="#kafka的请求分类" class="headerlink" title="kafka的请求分类"></a>kafka的请求分类</h3><p>之前，我们了解到 Kafka 是使用 TCP 进行通信，在TCP的基础上，Kafka定义了属于自己的请求协议：</p>
<p>比如常见的 PRODUCE 请求是用于生产消息的，FETCH 请求是用于消费消息的，METADATA 请求是用于请求 Kafka 集群元数据信息的等等</p>
<p>截止到 2.3 版本，总共有 45 种，在这 45 种请求中，可以分为两类：</p>
<p><strong>数据类请求</strong>：Kafka 社区把 PRODUCE 和 FETCH 这类请求称为数据类请求。</p>
<p><strong>控制类请求</strong>：Kafka 社区把 LeaderAndIsr、StopReplica 这类请求称为控制类请求。</p>
<h3 id="处理请求的方式"><a href="#处理请求的方式" class="headerlink" title="处理请求的方式"></a>处理请求的方式</h3><p>在传统的开发设计中，对一个请求的处理，很自然的就可以想到下面两种方式</p>
<h4 id="同步处理"><a href="#同步处理" class="headerlink" title="同步处理"></a>同步处理</h4><p>服务端收到一个消息，立即开始处理，处理完成后返回</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//伪代码</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">Request</span> request <span class="token operator">=</span> <span class="token function">accept</span><span class="token punctuation">(</span>connection<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">handle</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这个方法实现简单，但是有个致命的缺陷，那就是吞吐量太差。由于只能顺序处理每个请求，因此，每个请求都必须等待前一个请求处理完毕才能得到处理。这种方式只适用于请求发送非常不频繁的系统。</p>
<h4 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h4><p>既然同步的方式效率差， 那就用异步的方式</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token comment">//伪代码</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    <span class="token class-name">Request</span> <span class="token operator">=</span> request <span class="token operator">=</span> <span class="token function">accept</span><span class="token punctuation">(</span>connection<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">Thread</span> thread <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-></span> <span class="token punctuation">&#123;</span>
        <span class="token function">handle</span><span class="token punctuation">(</span>request<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    thread<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这个方法反其道而行之，完全采用异步的方式。系统会为每个入站请求都创建单独的线程来处理。这个方法的好处是，它是完全异步的，每个请求的处理都不会阻塞下一个请求。但缺陷也同样明显。为每个请求都创建线程的做法开销极大，在某些场景下甚至会压垮整个服务。</p>
<h3 id="Kafka-是如何处理请求的"><a href="#Kafka-是如何处理请求的" class="headerlink" title="Kafka 是如何处理请求的"></a>Kafka 是如何处理请求的</h3><p>Kafka 使用 Reactor 模式来处理请求</p>
<h4 id="什么是Reactor模式"><a href="#什么是Reactor模式" class="headerlink" title="什么是Reactor模式"></a>什么是Reactor模式</h4><p>Reactor 模式是 JUC 包的作者 Doug Lea 的作品，真不愧是大神。</p>
<p>简单来说，Reactor 模式是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。</p>
<p>Reactor 模式的架构如下图所示，图来自 Doug Lea 的PPT：<a href="#https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a>：</p>
<img src="kafka从入门到入土.assets/image-20230215172615962.png" alt="image-20230215172615962" style="zoom: 33%;" />

<p>多个 Client 客户端会发送请求给到 Reactor。</p>
<p>Reactor 有个请求分发线程 Dispatcher ，也就是图中的 Acceptor 线程，它会将不同的请求下发到多个工作线程中处理。</p>
<p>Dispatcher 是 Reactor 模式的一个概念，它的实现是：Acceptor 线程，所以它俩是指同一个东西。</p>
<p>Acceptor 线程只是用于请求分发，不涉及具体的逻辑处理，非常得轻量级，因此有很高的吞吐量表现。</p>
<p>而工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。</p>
<h4 id="Kafka-的Reactor模式"><a href="#Kafka-的Reactor模式" class="headerlink" title="Kafka 的Reactor模式"></a>Kafka 的Reactor模式</h4><img src="kafka从入门到入土.assets/image-20230215173456675.png" alt="image-20230215173456675" style="zoom:33%;" />

<p>Kafka 的 Broker 端有个 SocketServer 组件，类似于 Reactor 模式中的 Dispatcher。</p>
<p>它也有对应的 Acceptor 线程和一个工作线程池，只不过在 Kafka 中，这个工作线程池有个专属的名字，叫网络线程池。</p>
<p>Kafka 提供了 Broker 端参数 num.network.threads，用于调整该网络线程池的线程数。</p>
<p>num.network.threads 的默认值是 3，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求。</p>
<h5 id="在Reactor模式下怎么处理请求"><a href="#在Reactor模式下怎么处理请求" class="headerlink" title="在Reactor模式下怎么处理请求"></a>在Reactor模式下怎么处理请求</h5><img src="kafka从入门到入土.assets/image-20230215192742666.png" alt="image-20230215192742666" style="zoom:50%;" />



<p>上图，其中 1-7 步骤是处理请求， 7-10 是响应请求</p>
<p>1、客户端或者其他Broker发起请求，这里的请求可能是 数据类请求，也可能是 控制类请求</p>
<p>2、请求发送到 Broker，会由 SocketServer 组件开始处理</p>
<p>3、SocketServer 组件（Acceptor线程）开始处理</p>
<p>4、SocketServer 组件（Acceptor线程）会将请求分发到网络线程池，这是一个很轻量级的工作</p>
<p>5、网络线程池中的某个线程接收到请求，但是这个线程并不会开始处理，而是将当前请求发送到共享请求队列</p>
<p>6、Broker 端还有一个IO线程池，会不停的从共享请求队列中获取请求，这才是真正的开始处理请求</p>
<ul>
<li>Broker 端参数 num.io.threads 控制了这个线程池中的线程数。</li>
<li>目前该参数默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求</li>
<li>你可以根据实际硬件条件设置此线程池的个数</li>
</ul>
<p>7、这个请求如果是 PRODUCE 请求，就写入日志；如果是 FETCH 请求，就从磁盘或者页缓存中读取数据</p>
<h5 id="在Reactor模式下怎么响应请求"><a href="#在Reactor模式下怎么响应请求" class="headerlink" title="在Reactor模式下怎么响应请求"></a>在Reactor模式下怎么响应请求</h5><img src="kafka从入门到入土.assets/image-20230215192742666.png" alt="image-20230215192742666" style="zoom:50%;" />



<p>上图，其中 1-7 步骤是处理请求， 7-10 是响应请求</p>
<p>7、这个请求如果是 PRODUCE 请求，就写入日志；如果是 FETCH 请求，就从磁盘或者页缓存中读取数据</p>
<p>8、如果当前这个请求<strong>可以直接返回</strong>，就会找到当时发送这个请求的线程，然后返回到这个线程的响应队列中</p>
<ul>
<li><p>什么是可以直接返回的请求？ </p>
</li>
<li><blockquote>
<p>再讲什么是可以直接返回的请求之前，先了解一个什么是不可以直接返回的请求？</p>
<p>不可以直接返回的请求，比如设置了 acks&#x3D;all 的 PRODUCE 请求</p>
<p>一旦设置了 acks&#x3D;all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回</p>
<p>此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果</p>
<p>这就是不能直接返回的请求。</p>
<p>相反的，就是可以直接返回的请求</p>
</blockquote>
</li>
<li><p>响应队列是网络线程池中每个线程专属的吗？</p>
</li>
<li><blockquote>
<p>是的。</p>
<p>请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。</p>
<p>这么设计的原因就在于，Dispatcher 只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送 Response 给客户端，所以这些 Response 也就没必要放在一个公共的地方。</p>
</blockquote>
</li>
<li><p>怎么找到当时发送这个请求的线程呢？</p>
</li>
<li><blockquote>
<p>在源码中，有这部分代码逻辑：RequestChannel 类的 sendResponse 方法</p>
<p>&#x2F;&#x2F; 找出response对应的Processor线程，即request当初是由哪个Processor线程处理的 </p>
<p>val processor &#x3D; processors.get(response.processor) </p>
<p>&#x2F;&#x2F; 将response对象放置到对应Processor线程的Response队列中 </p>
<p>if (processor !&#x3D; null) { </p>
<p>  processor.enqueueResponse(response) </p>
<p>}</p>
</blockquote>
</li>
</ul>
<p>8、如果当前这个请求是<strong>不可以直接返回的</strong>，就会将当前这个请求暂存到 Purgatory</p>
<ul>
<li><p>什么是不可以直接返回的请求？ </p>
</li>
<li><blockquote>
<p>不可以直接返回的请求，比如设置了 acks&#x3D;all 的 PRODUCE 请求</p>
<p>一旦设置了 acks&#x3D;all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回</p>
<p>此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果</p>
<p>这就是不能直接返回的请求。</p>
<p>相反的，就是可以直接返回的请求</p>
</blockquote>
</li>
<li><p>Purgatory 是什么？</p>
</li>
<li><blockquote>
<p>Purgatory 的组件，这是 Kafka 中著名的“炼狱”组件。</p>
<p>它是用来缓存延时请求（Delayed Request）的。</p>
<p>所谓延时请求，就是那些一时未满足条件，不能立刻处理的请求。</p>
</blockquote>
</li>
</ul>
<p>9、等 Purgatory 中暂存的请求，可以返回的时候，会找到当时发送这个请求的线程，返回到这个线程的响应队列中</p>
<ul>
<li><p>怎么知道是可以返回的时候？</p>
</li>
<li><blockquote>
<p>举个例子：比如设置了 acks&#x3D;all 的 PRODUCE 请求</p>
<p>一旦设置了 acks&#x3D;all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回</p>
<p>此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果</p>
<p>此时才可以返回</p>
</blockquote>
</li>
</ul>
<p>10、网络线程池的线程，会将自己响应队列中的响应数据，通过网络传输回去。</p>
<h3 id="控制类和数据类请求分离"><a href="#控制类和数据类请求分离" class="headerlink" title="控制类和数据类请求分离"></a>控制类和数据类请求分离</h3><p>在本小节开头，就介绍过：Kafka 的请求分类两类</p>
<p><strong>数据类请求</strong>：Kafka 社区把 PRODUCE 和 FETCH 这类请求称为数据类请求。</p>
<p><strong>控制类请求</strong>：Kafka 社区把 LeaderAndIsr、StopReplica 这类请求称为控制类请求。</p>
<p>在了解了 Kafka 是怎么处理请求的流程之后，思考这么一个问题：</p>
<p>如果当前 共享请求队列 中，已经积压了很多的数据，IO线程正在马不停蹄的处理，此时我们发送一个请求：要求一个 Replica 下线。</p>
<p>此时：这个要求 Replica 下线的请求是优先处理，还是顺序处理？</p>
<p>如果是优先处理，那共享请求队列中积压的数据，怎么办？</p>
<p>如果是顺序处理，如果等待的时间很长很长，Replica 一直无法下线怎么办？</p>
<p>所以我们需要把 控制类请求 和 数据类请求 <strong>分开处理</strong>。</p>
<p>这就是 控制类和数据类请求分离</p>
<h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><p>举一个具体的场景：</p>
<p>假设我们有个主题只有 1 个分区，该分区配置了 2 个副本</p>
<p>其中 Leader 副本保存在 Broker 0 上，Follower 副本保存在 Broker 1 上</p>
<p>假设 Broker 0 这台机器积压了很多的 PRODUCE 请求</p>
<p>此时你如果使用 Kafka 命令强制将该主题分区的 Leader、Follower 角色互换</p>
<p>那么 Kafka 内部的控制器组件（Controller）会发送 LeaderAndIsr 请求给 Broker 0，显式地告诉它，当前它不再是 Leader，而是 Follower 了</p>
<p>而 Broker 1 上的 Follower 副本因为被选为新的 Leader，因此停止向 Broker 0 拉取消息</p>
<h4 id="不分离的现象"><a href="#不分离的现象" class="headerlink" title="不分离的现象"></a>不分离的现象</h4><p>如果 控制类请求 和 数据类请求 不分离</p>
<p>LeaderAndIsr 请求（ Leader、Follower 角色互换）就会放在 共享请求队列 的后面</p>
<p>如果 共享请求队列 积压了很多，我们就要等很长很长时间，才能处理到这个 控制类请求</p>
<p>很显然，这不是我们想要的结果</p>
<h4 id="分离的现象"><a href="#分离的现象" class="headerlink" title="分离的现象"></a>分离的现象</h4><p>如果 控制类请求 和 数据类请求 分离</p>
<p>那么在 LeaderAndIsr 发送之前积压的 PRODUCE 请求就都无法正常完成了。</p>
<p>这是我们想要的结果吗？</p>
<p>我不知道这是不是我们想要的结果，但这是目前 Kafka 的处理方式</p>
<p>Kafka 会优先处理 LeaderAndIsr 请求，Broker 0 就会立刻抛出 NOT_LEADER_FOR_PARTITION 异常，快速地标识这些积压 PRODUCE 请求已失败</p>
<h4 id="怎么设计分离"><a href="#怎么设计分离" class="headerlink" title="怎么设计分离"></a>怎么设计分离</h4><p>现在我们知道 Kafka 会优先处理 控制类请求，如果是你来设计，你会怎么让 Kafka 优先处理 控制类请求呢？</p>
<p>方案一：</p>
<p>在 Broker 中实现一个优先级队列，并赋予控制类请求更高的优先级。</p>
<p>这是很自然的想法，所以我本以为社区也会这么实现的，但后来我这个方案被清晰地记录在“已拒绝方案”列表中。</p>
<p>拒绝的原因在于，它无法处理请求队列已满的情形。当请求队列已经无法容纳任何新的请求时，纵然有优先级之分，它也无法处理新的控制类请求了</p>
<p>方案二：</p>
<p>直接将 控制类请求 替换 共享请求队列中 的最前面的数据，这样就可以优先处理控制类请求了，处理完控制类请求，再将这个数据类请求插队到队头；</p>
<p>这个方案是网友分享的，当然，Kafka 社区也没有采用这个方案</p>
<p>那么 Kafka 是怎么做的呢？</p>
<h4 id="Kafka是怎么分离的"><a href="#Kafka是怎么分离的" class="headerlink" title="Kafka是怎么分离的"></a>Kafka是怎么分离的</h4><p>那么，社区是如何解决的呢？</p>
<p>很简单，Kafka 社区实现了两套一模一样的 Reactor模型</p>
<p>一个用来处理 数据类型请求，一个用来处理 控制类请求；实现了两类请求的分离。</p>
<p>也就是说，Kafka Broker 启动后，会在后台分别创建两套网络线程池和 IO 线程池的组合，它们分别处理数据类请求和控制类请求。</p>
<p>至于所用的 Socket 端口，自然是使用不同的端口了，你需要提供不同的 listeners 配置，显式地指定哪套端口用于处理哪类请求。</p>
<h2 id="kafka控制器"><a href="#kafka控制器" class="headerlink" title="kafka控制器"></a>kafka控制器</h2><h2 id="关于高水位和Leader-Epoch的讨论"><a href="#关于高水位和Leader-Epoch的讨论" class="headerlink" title="关于高水位和Leader Epoch的讨论"></a>关于高水位和Leader Epoch的讨论</h2><p>高水位和低水位分别是什么</p>
<p>HW</p>
<p>LEO（Log End Offet）</p>
<p>LSO（Log Stable Offset）：事务生产者</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>为什么kafka不像mysql那样允许追随者副本（follower replica）对外提供只读服务？</p>
<p>kafka是怎么做到 提供一套 API 实现生产者和消费者？</p>
<p>kafka是怎么做到 降低网络传输和磁盘存储开销；</p>
<p>kafka是怎么做到 实现高伸缩性架构。</p>
<p>kafka为什么快，为什么高吞吐？</p>
<ul>
<li>消息日志（Log）只能追加写，避免了随机IO，改成了顺序IO，大大提高了写能力；</li>
</ul>
<p>你觉得 Kafka 未来的演进路线是怎么样的？如果你是 Kafka 社区的“掌舵人”，你准备带领整个社区奔向什么方向呢？</p>
<p>想你是一家创业公司的架构师，公司最近准备改造现有系统，引入 Kafka 作为消息中间件衔接上下游业务。作为架构师的你会怎么选择合适的 Kafka 发行版呢</p>
<p>kafka每天 1 亿条 1KB 大小的消息，保存两份且留存两周的时间，需要多大的磁盘空间？</p>
<p>如果需要kafka1小时内处理1TB的业务数据，在千兆网络下，需要多少台kafka机器？</p>
<p>kafka怎么实现的故障转移？</p>
<p>kafka是怎么保障大数据量均匀的分布在各个Broker上的？</p>
<p>kafka的零拷贝技术是什么？</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/ljheee/article/details/99652448">https://blog.csdn.net/ljheee/article/details/99652448</a></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/835ec2d4c170">https://www.jianshu.com/p/835ec2d4c170</a></li>
</ul>
<p>broker端收到消息也会解压缩，进行消息校验，那么零拷贝还有用嘛？</p>
<p>consumer可以先提交offset，在处理消息嘛？</p>
<p>kafka的producer是在producer实例化的时候，创建的TCP连接，那么这个时候，producer都不知道要往那个topic发消息，那么就不知道要连接到哪个broker？kafka是怎么做的呢？</p>
<p>kafka在建立TCP连接的步骤中，有没有可以优化的地方，目前社区做的不好的地方？</p>
<p>丰网的kafka的消费者重复注册是怎么做的？是同一个消费者实例的多个线程，还是同一个消费者类，注册了多个bean；</p>
<p>重试机制会导致消息乱序吗？</p>
<ul>
<li>重试机制不会重新计算Partition信息</li>
<li>重试机制会导致消息乱序，但是可以通过 max.in.flight.requests.per.connection&#x3D;1 来避免，但是会导致吞吐量下降</li>
<li>max.in.flight.requests.per.connection：表示限制客户端在单个连接上能够发送的未响应请求的个数；</li>
<li>设置为 1 表示：broker收到一个请求之后，在响应之前，是不会接收别的请求的</li>
</ul>
<p>消息的分区位移是什么时候写入的？</p>
<p>如果一个消息写入失败了，Producer 有重试，它的Offset是新的，还是老的？</p>
<p>Consumer设置自动提交位移，有一个提交频率，具体的流程是怎么提交的，如果消费到了Producer重试的消息，Offset会怎么样？</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka/">kafka</a><a class="post-meta__tags" href="/tags/%E7%94%9F%E4%BA%A7%E8%80%85/">生产者</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E8%B4%B9%E8%80%85/">消费者</a><a class="post-meta__tags" href="/tags/%E6%B6%88%E6%81%AF/">消息</a><a class="post-meta__tags" href="/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/">中间件</a></div><div class="post_share"></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%85%A5%E5%9C%9F"><span class="toc-number">1.</span> <span class="toc-text">kafka从入门到入土</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8D%E8%AF%8D%E6%9C%AF%E8%AF%AD"><span class="toc-number">1.1.1.</span> <span class="toc-text">名词术语</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E5%B1%82%E6%B6%88%E6%81%AF%E6%9E%B6%E6%9E%84"><span class="toc-number">1.1.2.</span> <span class="toc-text">三层消息架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%EF%BC%88Log%EF%BC%89"><span class="toc-number">1.1.3.</span> <span class="toc-text">数据持久化（Log）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E7%A7%8D%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.4.</span> <span class="toc-text">两种消息模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2%E5%92%8C%E5%AE%9A%E4%BD%8D"><span class="toc-number">1.2.</span> <span class="toc-text">发展历史和定位</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><span class="toc-number">1.2.1.</span> <span class="toc-text">发展历史</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E5%85%B6%E4%BB%96%E7%9A%84%E6%B5%81%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">1.2.2.</span> <span class="toc-text">与其他的流处理框架的优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D"><span class="toc-number">1.2.3.</span> <span class="toc-text">定位</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.</span> <span class="toc-text">kafka版本</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E8%A1%8C%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.1.</span> <span class="toc-text">发行版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%88%E6%9C%AC%E5%8F%B7"><span class="toc-number">1.3.2.</span> <span class="toc-text">版本号</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#0-7%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">0.7版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0-8%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">0.8版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0-9%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">0.9版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0-10%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">0.10版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#0-11%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.5.</span> <span class="toc-text">0.11版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-0-x2F-2-0%E7%89%88%E6%9C%AC"><span class="toc-number">1.3.2.6.</span> <span class="toc-text">1.0&#x2F;2.0版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.3.2.7.</span> <span class="toc-text">建议</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2"><span class="toc-number">1.4.</span> <span class="toc-text">kafka生产集群部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.4.1.</span> <span class="toc-text">操作系统的选择</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IO%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">IO模型的使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E6%95%88%E7%8E%87"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">网络传输效率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BE%E5%8C%BA%E7%9A%84%E6%94%AF%E6%8C%81%E5%BA%A6"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">社区的支持度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.4.2.</span> <span class="toc-text">磁盘的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E5%AE%B9%E9%87%8F%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.4.3.</span> <span class="toc-text">磁盘容量的选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%A6%E5%AE%BD%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.4.4.</span> <span class="toc-text">带宽的选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E7%9A%84%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.</span> <span class="toc-text">重要的集群参数配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#broker%E7%AB%AF%E5%8F%82%E6%95%B0%EF%BC%88%E9%9D%99%E6%80%81%E5%8F%82%E6%95%B0%EF%BC%89"><span class="toc-number">1.5.1.</span> <span class="toc-text">broker端参数（静态参数）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E4%BF%A1%E6%81%AF%E7%B1%BB%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">存储信息类参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8EZK%E7%9B%B8%E5%85%B3%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">与ZK相关的参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#broker%E8%BF%9E%E6%8E%A5%E7%9B%B8%E5%85%B3%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">broker连接相关的参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#topic%E7%AE%A1%E7%90%86%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">topic管理的参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%95%99%E5%AD%98%E6%96%B9%E9%9D%A2%E7%9A%84%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">数据留存方面的参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Topic%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.2.</span> <span class="toc-text">Topic的参数配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%95%99%E5%AD%98%E6%96%B9%E9%9D%A2%E7%9A%84%E5%8F%82%E6%95%B0-1"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">数据留存方面的参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E4%BF%AE%E6%94%B9topic%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">怎么修改topic的参数配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JVM%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.3.</span> <span class="toc-text">JVM的参数配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%AF%B9kafka%E8%AE%BE%E7%BD%AEJVM%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">怎么对kafka设置JVM参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.4.</span> <span class="toc-text">操作系统的参数配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E6%9C%BA%E5%88%B6"><span class="toc-number">1.6.</span> <span class="toc-text">分区机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%88%86%E5%8C%BA"><span class="toc-number">1.6.1.</span> <span class="toc-text">为什么要分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.6.2.</span> <span class="toc-text">分区策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%AE%BE%E7%BD%AE%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.6.3.</span> <span class="toc-text">怎么设置分区策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E5%8E%8B%E7%BC%A9%EF%BC%88%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F%EF%BC%89"><span class="toc-number">1.7.</span> <span class="toc-text">消息压缩（消息格式）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%8E%8B%E7%BC%A9%EF%BC%9F"><span class="toc-number">1.7.1.</span> <span class="toc-text">为什么要压缩？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka%E7%9A%84%E6%B6%88%E6%81%AF%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.7.2.</span> <span class="toc-text">kafka的消息格式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.7.3.</span> <span class="toc-text">怎么压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%95%E6%97%B6%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.7.4.</span> <span class="toc-text">何时压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%95%E6%97%B6%E8%A7%A3%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.7.5.</span> <span class="toc-text">何时解压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%97%B6%E6%9C%BA"><span class="toc-number">1.7.6.</span> <span class="toc-text">压缩的时机</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.7.7.</span> <span class="toc-text">压缩算法的选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.8.</span> <span class="toc-text">消息丢失</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.8.1.</span> <span class="toc-text">什么是消息丢失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.8.2.</span> <span class="toc-text">什么时候会消息丢失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1"><span class="toc-number">1.8.3.</span> <span class="toc-text">怎么保证消息不丢失</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.9.</span> <span class="toc-text">拦截器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.9.1.</span> <span class="toc-text">生产者拦截器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.9.2.</span> <span class="toc-text">消费者拦截器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">1.9.3.</span> <span class="toc-text">配置拦截器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%B8%8ETCP%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.10.</span> <span class="toc-text">生产者与TCP连接</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%87%E7%94%A8TCP%E4%BD%9C%E4%B8%BA%E5%BA%95%E5%B1%82%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.10.1.</span> <span class="toc-text">为什么采用TCP作为底层传输协议</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%98%AF%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%88%9B%E5%BB%BATCP%E8%BF%9E%E6%8E%A5%E7%9A%84"><span class="toc-number">1.10.2.</span> <span class="toc-text">生产者是什么时候创建TCP连接的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%9B%E5%BB%BATCP%E8%BF%9E%E6%8E%A5%E7%9A%84"><span class="toc-number">1.10.3.</span> <span class="toc-text">是怎么创建TCP连接的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TCP%E8%BF%9E%E6%8E%A5%E6%98%AF%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E8%A2%AB%E5%85%B3%E9%97%AD%E7%9A%84"><span class="toc-number">1.10.4.</span> <span class="toc-text">TCP连接是什么时候被关闭的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%9A%E5%AD%98%E5%9C%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="toc-number">1.10.5.</span> <span class="toc-text">会存在的一些问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8ETCP%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.11.</span> <span class="toc-text">消费者与TCP连接</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%98%AF%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%88%9B%E5%BB%BATCP%E8%BF%9E%E6%8E%A5%E7%9A%84"><span class="toc-number">1.11.1.</span> <span class="toc-text">消费者是什么时候创建TCP连接的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%A4%9A%E5%B0%91%E4%B8%AATCP%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.11.2.</span> <span class="toc-text">创建多少个TCP连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%98%AF%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%85%B3%E9%97%ADTCP%E8%BF%9E%E6%8E%A5%E7%9A%84"><span class="toc-number">1.11.3.</span> <span class="toc-text">消费者是什么时候关闭TCP连接的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.11.4.</span> <span class="toc-text">可能存在的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">1.12.</span> <span class="toc-text">幂等和事务生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E4%BA%A4%E4%BB%98%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="toc-number">1.12.1.</span> <span class="toc-text">消息交付可靠性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%9A%84%E6%A6%82%E5%BF%B5"><span class="toc-number">1.12.2.</span> <span class="toc-text">幂等和事务的概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">1.12.3.</span> <span class="toc-text">幂等生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="toc-number">1.12.3.1.</span> <span class="toc-text">幂等生产者的使用方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">1.12.3.2.</span> <span class="toc-text">幂等生产者的实现原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%82%E7%AD%89%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E4%BD%9C%E7%94%A8%E8%8C%83%E5%9B%B4"><span class="toc-number">1.12.3.3.</span> <span class="toc-text">幂等生产者的作用范围</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">1.12.4.</span> <span class="toc-text">事务生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="toc-number">1.12.4.1.</span> <span class="toc-text">事务生产者的使用方式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">1.12.4.2.</span> <span class="toc-text">事务生产者的实现原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%92%8C%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">1.13.</span> <span class="toc-text">消费者组和独立消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84"><span class="toc-number">1.13.1.</span> <span class="toc-text">什么是消费者组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%95%E5%85%A5%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84"><span class="toc-number">1.13.2.</span> <span class="toc-text">为什么要引入消费者组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%9A%84%E9%87%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.13.3.</span> <span class="toc-text">消费者的重平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E7%89%B9%E6%80%A7%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.13.4.</span> <span class="toc-text">消费者组的特性是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%B6%88%E6%81%AF%E5%BC%95%E6%93%8E%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.13.5.</span> <span class="toc-text">传统的消息引擎模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F"><span class="toc-number">1.13.6.</span> <span class="toc-text">消费者组的使用方式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%98%AF%E5%A6%82%E4%BD%95%E7%BB%B4%E6%8A%A4offset%E7%9A%84"><span class="toc-number">1.13.7.</span> <span class="toc-text">消费者组是如何维护offset的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">1.13.8.</span> <span class="toc-text">独立消费者</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E5%92%8C%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98"><span class="toc-number">1.14.</span> <span class="toc-text">位移和位移主题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BD%8D%E7%A7%BB%E5%92%8C%E5%88%86%E5%8C%BA%E4%BD%8D%E7%A7%BB"><span class="toc-number">1.14.1.</span> <span class="toc-text">消费者位移和分区位移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BD%8D%E7%A7%BB"><span class="toc-number">1.14.2.</span> <span class="toc-text">消费者位移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98"><span class="toc-number">1.14.3.</span> <span class="toc-text">位移主题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98"><span class="toc-number">1.14.3.1.</span> <span class="toc-text">为什么会有位移主题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.14.3.2.</span> <span class="toc-text">位移主题是什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%88%9B%E5%BB%BA"><span class="toc-number">1.14.3.3.</span> <span class="toc-text">位移主题什么时候创建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E7%9A%84%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC"><span class="toc-number">1.14.3.4.</span> <span class="toc-text">位移主题的分区和副本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%B8%AD%E5%AD%98%E4%BA%86%E4%BB%80%E4%B9%88"><span class="toc-number">1.14.3.5.</span> <span class="toc-text">位移主题中存了什么</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E6%8F%90%E4%BA%A4offset%E5%88%B0%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98"><span class="toc-number">1.14.3.6.</span> <span class="toc-text">怎么提交offset到位移主题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB"><span class="toc-number">1.14.3.6.1.</span> <span class="toc-text">自动提交位移</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB"><span class="toc-number">1.14.3.6.2.</span> <span class="toc-text">手动提交位移</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F"><span class="toc-number">1.14.3.6.2.1.</span> <span class="toc-text">同步提交方式</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F"><span class="toc-number">1.14.3.6.2.2.</span> <span class="toc-text">异步提交方式</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F-%E5%BC%82%E6%AD%A5%E6%8F%90%E4%BA%A4%E6%96%B9%E5%BC%8F"><span class="toc-number">1.14.3.6.2.3.</span> <span class="toc-text">同步提交方式+异步提交方式</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%85%AC%E5%8F%B8%E5%86%85%E9%83%A8%E4%BD%BF%E7%94%A8"><span class="toc-number">1.14.3.6.3.</span> <span class="toc-text">公司内部使用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Offset%E6%8F%90%E4%BA%A4%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.14.3.6.4.</span> <span class="toc-text">Offset提交导致的问题</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%B8%AD%E7%9A%84%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE%EF%BC%88%E8%BF%87%E6%9C%9F%E4%BD%8D%E7%A7%BB%EF%BC%89"><span class="toc-number">1.14.3.7.</span> <span class="toc-text">位移主题中的过期数据（过期位移）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%E4%B8%AD%E7%9A%84%E8%BF%87%E6%9C%9F%E6%95%B0%E6%8D%AE%EF%BC%88%E8%BF%87%E6%9C%9F%E4%BD%8D%E7%A7%BB%EF%BC%89%E6%B8%85%E7%90%86"><span class="toc-number">1.14.3.8.</span> <span class="toc-text">位移主题中的过期数据（过期位移）清理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E5%A4%B1%E8%B4%A5%E6%80%8E%E4%B9%88%E5%8A%9E"><span class="toc-number">1.14.3.9.</span> <span class="toc-text">位移提交失败怎么办</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9"><span class="toc-number">1.15.</span> <span class="toc-text">多线程消费</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Java-Consumer-%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.15.1.</span> <span class="toc-text">Kafka Java Consumer 的单线程设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%96%B9%E6%A1%88"><span class="toc-number">1.15.2.</span> <span class="toc-text">多线程方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%B8%80"><span class="toc-number">1.15.2.1.</span> <span class="toc-text">方案一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E4%BA%8C"><span class="toc-number">1.15.2.2.</span> <span class="toc-text">方案二</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94"><span class="toc-number">1.15.2.3.</span> <span class="toc-text">方案对比</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.15.2.4.</span> <span class="toc-text">代码实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E4%B8%8E%E5%8D%8F%E8%B0%83%E8%80%85"><span class="toc-number">1.16.</span> <span class="toc-text">重平衡与协调者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%87%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.16.1.</span> <span class="toc-text">什么是重平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E9%87%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.16.2.</span> <span class="toc-text">什么时候会重平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E7%AD%96%E7%95%A5"><span class="toc-number">1.16.3.</span> <span class="toc-text">重平衡策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%8F%E8%B0%83%E8%80%85Coordinator"><span class="toc-number">1.16.4.</span> <span class="toc-text">什么是协调者Coordinator</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%BE%E5%88%B0%E8%87%AA%E5%B7%B1%E7%9A%84coordinator%E7%9A%84"><span class="toc-number">1.16.5.</span> <span class="toc-text">消费者组是怎么找到自己的coordinator的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E7%BC%BA%E7%82%B9"><span class="toc-number">1.16.6.</span> <span class="toc-text">重平衡的缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%BF%E5%85%8D%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">1.16.7.</span> <span class="toc-text">避免消费者组重平衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E6%8E%92%E6%9F%A5%E7%94%9F%E4%BA%A7%E6%98%AF%E5%90%A6%E9%87%8D%E5%B9%B3%E8%A1%A1%E8%BF%87%E5%A4%9A"><span class="toc-number">1.16.8.</span> <span class="toc-text">怎么排查生产是否重平衡过多</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%A0%B8%E5%BF%83%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">1.16.9.</span> <span class="toc-text">重平衡核心全流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E7%9A%84%E7%8A%B6%E6%80%81%E6%9C%BA"><span class="toc-number">1.16.9.1.</span> <span class="toc-text">消费者组的状态机</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%B5%81%E7%A8%8B"><span class="toc-number">1.16.9.2.</span> <span class="toc-text">重平衡流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%B8%80%EF%BC%9A%E6%96%B0%E6%88%90%E5%91%98%E5%85%A5%E7%BB%84"><span class="toc-number">1.16.9.2.1.</span> <span class="toc-text">场景一：新成员入组</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%BA%8C%EF%BC%9A%E7%BB%84%E6%88%90%E5%91%98%E4%B8%BB%E5%8A%A8%E7%A6%BB%E7%BB%84"><span class="toc-number">1.16.9.2.2.</span> <span class="toc-text">场景二：组成员主动离组</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E4%B8%89%EF%BC%9A%E7%BB%84%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84"><span class="toc-number">1.16.9.2.3.</span> <span class="toc-text">场景三：组成员崩溃离组</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E5%9B%9B%EF%BC%9A%E9%87%8D%E5%B9%B3%E8%A1%A1%E6%97%B6%E5%8D%8F%E8%B0%83%E8%80%85%E5%AF%B9%E7%BB%84%E5%86%85%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-number">1.16.9.2.4.</span> <span class="toc-text">场景四：重平衡时协调者对组内成员提交位移的处理</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98"><span class="toc-number">1.16.9.3.</span> <span class="toc-text">重平衡的一些问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-number">1.17.</span> <span class="toc-text">副本机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%89%AF%E6%9C%AC"><span class="toc-number">1.17.1.</span> <span class="toc-text">什么是副本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%AF%E6%9C%AC%E4%B9%8B%E9%97%B4%E6%95%B0%E6%8D%AE%E6%98%AF%E6%80%8E%E4%B9%88%E5%90%8C%E6%AD%A5%E7%9A%84"><span class="toc-number">1.17.2.</span> <span class="toc-text">副本之间数据是怎么同步的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Follower%E4%B8%8D%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">1.17.3.</span> <span class="toc-text">Follower不提供服务的优点</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E4%BE%BF%E5%AE%9E%E7%8E%B0%E2%80%9CRead-your-writes%E2%80%9D"><span class="toc-number">1.17.3.1.</span> <span class="toc-text">方便实现“Read-your-writes”</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E4%BE%BF%E5%AE%9E%E7%8E%B0%E5%8D%95%E8%B0%83%E8%AF%BB%EF%BC%88Monotonic-Reads%EF%BC%89"><span class="toc-number">1.17.3.2.</span> <span class="toc-text">方便实现单调读（Monotonic Reads）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81-%E5%89%AF%E6%9C%AC%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">1.17.4.</span> <span class="toc-text">怎么保证 副本数据一致性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#In-Sync-Replicas%EF%BC%88ISR%EF%BC%89"><span class="toc-number">1.17.4.1.</span> <span class="toc-text">In-Sync Replicas（ISR）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ISR%E6%98%AF%E6%80%8E%E4%B9%88%E5%8F%98%E5%8C%96%E7%9A%84"><span class="toc-number">1.17.4.2.</span> <span class="toc-text">ISR是怎么变化的</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%BF%9B%E8%A1%8C%E9%80%89%E4%B8%BE%E6%96%B0%E7%9A%84-Leader-Replica"><span class="toc-number">1.17.5.</span> <span class="toc-text">怎么进行选举新的 Leader Replica</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E6%B1%82%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E5%A4%84%E7%90%86%E7%9A%84"><span class="toc-number">1.18.</span> <span class="toc-text">请求是怎么被处理的</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka%E7%9A%84%E8%AF%B7%E6%B1%82%E5%88%86%E7%B1%BB"><span class="toc-number">1.18.1.</span> <span class="toc-text">kafka的请求分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82%E7%9A%84%E6%96%B9%E5%BC%8F"><span class="toc-number">1.18.2.</span> <span class="toc-text">处理请求的方式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E5%A4%84%E7%90%86"><span class="toc-number">1.18.2.1.</span> <span class="toc-text">同步处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86"><span class="toc-number">1.18.2.2.</span> <span class="toc-text">异步处理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-%E6%98%AF%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82%E7%9A%84"><span class="toc-number">1.18.3.</span> <span class="toc-text">Kafka 是如何处理请求的</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFReactor%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.18.3.1.</span> <span class="toc-text">什么是Reactor模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka-%E7%9A%84Reactor%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.18.3.2.</span> <span class="toc-text">Kafka 的Reactor模式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8Reactor%E6%A8%A1%E5%BC%8F%E4%B8%8B%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82"><span class="toc-number">1.18.3.2.1.</span> <span class="toc-text">在Reactor模式下怎么处理请求</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8Reactor%E6%A8%A1%E5%BC%8F%E4%B8%8B%E6%80%8E%E4%B9%88%E5%93%8D%E5%BA%94%E8%AF%B7%E6%B1%82"><span class="toc-number">1.18.3.2.2.</span> <span class="toc-text">在Reactor模式下怎么响应请求</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E7%B1%BB%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E8%AF%B7%E6%B1%82%E5%88%86%E7%A6%BB"><span class="toc-number">1.18.4.</span> <span class="toc-text">控制类和数据类请求分离</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF"><span class="toc-number">1.18.4.1.</span> <span class="toc-text">场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8D%E5%88%86%E7%A6%BB%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">1.18.4.2.</span> <span class="toc-text">不分离的现象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%A6%BB%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">1.18.4.3.</span> <span class="toc-text">分离的现象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1%E5%88%86%E7%A6%BB"><span class="toc-number">1.18.4.4.</span> <span class="toc-text">怎么设计分离</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Kafka%E6%98%AF%E6%80%8E%E4%B9%88%E5%88%86%E7%A6%BB%E7%9A%84"><span class="toc-number">1.18.4.5.</span> <span class="toc-text">Kafka是怎么分离的</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="toc-number">1.19.</span> <span class="toc-text">kafka控制器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E9%AB%98%E6%B0%B4%E4%BD%8D%E5%92%8CLeader-Epoch%E7%9A%84%E8%AE%A8%E8%AE%BA"><span class="toc-number">1.20.</span> <span class="toc-text">关于高水位和Leader Epoch的讨论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">1.21.</span> <span class="toc-text">问题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By zs</div></div><script src="https://cdn.bootcdn.net/ajax/libs/mermaid/9.4.0/mermaid.min.js"></script></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>